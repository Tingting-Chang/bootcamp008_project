{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getrevs(x):\n",
    "    times = []\n",
    "    for el in range(len(x.find_all('div', {'itemprop' : \"reviewRating\"}))):\n",
    "        times.append([str((x.find_all('meta', {'itemprop' : \"ratingValue\"}))[el].getText()), str(x.find_all('time')[el].getText())])\n",
    "    return times\n",
    "\n",
    "\n",
    "def getname(x):\n",
    "    m = x.find('h1', {'class' : \"recipe-summary__h1\"})\n",
    "    return str(m.get_text())\n",
    "\n",
    "getingredients = lambda x: [tag.get_text() for tag in x.find_all('span', {'class' : \"recipe-ingred_txt added\"})]\n",
    "\n",
    "getstars = lambda x: float(x.find('div', {'class': 'rating-stars'})[\"data-ratingstars\"])\n",
    "\n",
    "getnutrients = lambda x: [tag.get_text() for tag in x.find_all('li', {'class': \"nutrientLine__item--amount\"})]\n",
    "\n",
    "def getpiccount(bso):\n",
    "    m =  bso.find_all('span', {'class' : \"picture-count\"})[0].find('format-large-number')\n",
    "    return int(re.search('\"(.*)\"', str(m)).groups()[0])\n",
    "\n",
    "def getrevcount(x):\n",
    "    s = [tag.get_text() for tag in x.find_all('span', {'class' : \"review-count\"})]\n",
    "    return re.split(' ',(s[0]))[0]\n",
    "\n",
    "def getdesc(x): \n",
    "    return x.find('div', {'class' : \"submitter__description\"}).get_text()\n",
    "getprep = lambda x: [tag.get_text() for tag in x.find_all('span', {'class' : \"prepTime__item--time\"})]\n",
    "addit = lambda x: df1.append(doeverything(x), ignore_index = True)\n",
    "\n",
    "def gettimes(x):\n",
    "    times = {}\n",
    "    for el in range(len(x.find_all('p', {'class' : \"prepTime__item--type\"}))):\n",
    "        times[str((x.find_all('p', {'class' : \"prepTime__item--type\"}))[el].getText())] = str(x.find_all('time')[el].getText())\n",
    "    return times\n",
    "\n",
    "def rating_date(x):\n",
    "    text = requests.get(x).text\n",
    "    u = BeautifulSoup(text)\n",
    "    rd = []\n",
    "    for i in range(len(u.find_all('div', {'class' : \"stars-and-date-container\"}))-2):\n",
    "        D = u.find_all('div', {'class' : \"stars-and-date-container\"})[i+1].find('meta', {'itemprop' : 'dateCreated'})['content']\n",
    "        R = u.find_all('div', {'class' : \"stars-and-date-container\"})[i+1].find('div', {'class' : 'rating-stars'})['data-ratingstars']\n",
    "        rd.append([R, D])\n",
    "    return ([getname(u), rd])\n",
    "\n",
    "\n",
    "def main(u):\n",
    "    text = requests.get(u).text\n",
    "    x = BeautifulSoup(text, \"lxml\")\n",
    "    name = getname(x)\n",
    "    rating =  getstars(x)\n",
    "    revcount =  getrevcount(x)\n",
    "    ingredients = getingredients(x)\n",
    "    nutrients = getnutrients(x)\n",
    "    pics = getpiccount(x)\n",
    "    times = (gettimes(x))\n",
    "    description = str(getdesc(x).rstrip('\\n')).translate(string.maketrans(\"\",\"\"), string.punctuation)\n",
    "    return str(name), str(rating), str(revcount), str(nutrients), str(pics), str(times), str(ingredients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "def selen_main(url):\n",
    "    try:\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(15)\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        while soup.find(\"div\", {\"class\": \"more-button\"}):\n",
    "            try:\n",
    "                driver.find_element_by_xpath('//div[@class=\"more-button\"]').click()\n",
    "            except Exception as e:\n",
    "                print 'Couldn''t click button for some reason...'\n",
    "                break\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        with open('lasagnaDT.csv', 'a+') as g:\n",
    "            writer = csv.writer(g)\n",
    "            data = rating_date(soup)\n",
    "            data = map(lambda s: s.encode('utf-8'), data)\n",
    "            writer.writerow(data)\n",
    "    except Exception as e:\n",
    "        print 'e'\n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.close()\n",
    "            driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasagna = []\n",
    "e = open('/Users/ethanweber/Desktop/Untitled Folder/data copy/splitpea2.txt','r').readlines()\n",
    "for line in e:\n",
    "    lasagna.append(line.rstrip('\\n'))\n",
    "len(lasagna)\n",
    "m = 0\n",
    "\n",
    "\n",
    "for i in lasagna:\n",
    "    import csv\n",
    "    try: \n",
    "        with open('sp_output.txt', 'a+') as f:\n",
    "            f.write('|'.join(main(i)))\n",
    "            f.write(\"\\n\")\n",
    "            m += 1\n",
    "            print(m, 'is finished')\n",
    "    except:\n",
    "        #error message\n",
    "        pass\n",
    "    \n",
    "df = pd.DataFrame()\n",
    "with open('sp_output.txt', 'rb') as csvfile:\n",
    "    rowreader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in rowreader:\n",
    "        df = df.append(pd.Series(row), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'is finished')\n",
      "(2, 'is finished')\n",
      "(3, 'is finished')\n",
      "(4, 'is finished')\n",
      "(5, 'is finished')\n",
      "(6, 'is finished')\n",
      "(7, 'is finished')\n",
      "(8, 'is finished')\n",
      "(9, 'is finished')\n",
      "(10, 'is finished')\n",
      "(11, 'is finished')\n",
      "(12, 'is finished')\n",
      "(13, 'is finished')\n",
      "(14, 'is finished')\n",
      "(15, 'is finished')\n",
      "(16, 'is finished')\n",
      "(17, 'is finished')\n",
      "(18, 'is finished')\n",
      "(19, 'is finished')\n",
      "(20, 'is finished')\n",
      "(21, 'is finished')\n",
      "(22, 'is finished')\n",
      "(23, 'is finished')\n",
      "(24, 'is finished')\n",
      "(25, 'is finished')\n",
      "(26, 'is finished')\n",
      "(27, 'is finished')\n",
      "(28, 'is finished')\n",
      "(29, 'is finished')\n",
      "(30, 'is finished')\n",
      "(31, 'is finished')\n",
      "(32, 'is finished')\n",
      "(33, 'is finished')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "with open('sp_output.txt', 'rb') as csvfile:\n",
    "    rowreader = csv.reader(csvfile, delimiter='|')\n",
    "    for row in rowreader:\n",
    "        df = df.append(pd.Series(row), ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 kcal', \n",
      "253 kcal', \n",
      "212 kcal', \n",
      "283 kcal', \n",
      "487 kcal', \n",
      "189 kcal', \n",
      "210 kcal', \n",
      "450 kcal', \n",
      "348 kcal', \n",
      "413 kcal', \n",
      "613 kcal', \n",
      "216 kcal', \n",
      "247 kcal', \n",
      "641 kcal', \n",
      "364 kcal', \n",
      "434 kcal', \n",
      "65 kcal', \n",
      "156 kcal', \n",
      "374 kcal', \n",
      "562 kcal', \n",
      "412 kcal', \n",
      "170 kcal', \n",
      "386 kcal', \n",
      "509 kcal', \n",
      "133 kcal', \n",
      "510 kcal', \n",
      "273 kcal', \n",
      "423 kcal', \n",
      "205 kcal', \n",
      "219 kcal', \n",
      "120 kcal', \n",
      "201 kcal', \n",
      "371 kcal', \n"
     ]
    }
   ],
   "source": [
    "for i in df.loc[ : , 3]:\n",
    "    i = str(i).split(\"u'\")\n",
    "    print i[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanweber/anaconda/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /Users/ethanweber/anaconda/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'\\r\\n\"Making this lasagna a day ahead and refrigerating overnight allows the spices to meld, and gives it exceptional flavor.\"        '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getpiccount(x):\n",
    "    m =  x.find_all('span', {'class' : \"picture-count\"})[0].find('format-large-number')\n",
    "    return int(re.search('\"(.*)\"', str(m)).groups()[0])\n",
    "#int(re.search('\"(.*)\"', str(tester(t))).groups()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-288-361dad58f06b>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-288-361dad58f06b>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    print('{0}: {1}, '.format(k, ss[k]), end='')\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extend() takes exactly one argument (0 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-515857fd9d86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetdesc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mlasagna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0msid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlasagna\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: extend() takes exactly one argument (0 given)"
     ]
    }
   ],
   "source": [
    "#<span class=\"review-count\">1777 reviews</span>\n",
    "t = 'http://allrecipes.com/recipe/11729/american-lasagna/?internalSource=staff%20pick&referringId=502&referringContentType=recipe%20hub&clickId=cardslot%204'\n",
    "def tester(url):\n",
    "    text = requests.get(url).text\n",
    "    x = BeautifulSoup(text)\n",
    "    return getdesc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brown Rice and Black Bean Salad\n",
      "Restaurant Style Red Beans and Rice\n",
      "Quick and Easy Black Beans and Rice\n",
      "Black Beans, Corn, and Yellow Rice\n",
      "Fresh Tasting Black Beans With Rice\n",
      "Cajun Style Red Bean and Rice Soup\n",
      "Texi-Fied Black Beans and Brown Rice\n",
      "Easy Rum-Flavored Black Beans and Rice\n",
      "Middle Eastern Rice with Black Beans and Chickpeas\n"
     ]
    }
   ],
   "source": [
    "m = ('http://allrecipes.com/recipe/245073/ranch-meatloaf/?internalSource=hub%20recipe&referringContentType=search%20results&clickId=cardslot%202')\n",
    "def getdesc(x): \n",
    "    return x.find('div', {'class' : \"submitter__description\"}).get_text()\n",
    "def tester(url):\n",
    "    text = requests.get(url).text\n",
    "    x = BeautifulSoup(text)\n",
    "    return str(getname(x))\n",
    "for i in lasagna:\n",
    "    print tester(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lasagna)):\n",
    "    import csv\n",
    "    with open('lasagnadata.csv', 'a+') as f:\n",
    "        writer = csv.writer(f)\n",
    "        try:\n",
    "            lasagna_data = main(lasagna[i])\n",
    "        except:\n",
    "            print 'no lasagna_data'\n",
    "            lasagna_data = ''\n",
    "        #if lasagna[i] != None:\n",
    "        #    lasagna_data = main(lasagna[i])\n",
    "            writer.writerow(lasagna_data)\n",
    "    #if (i % 5) == 0:\n",
    "    #    with open('lasagnaDT.csv', 'a+') as g:\n",
    "    #        writer = csv.writer(g)\n",
    "    #        writer.writerow() #selen_main(lasagna[i])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
