{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "# Anonymous Hedge - Kamal Sandhu & Abhishek Desai\n",
    "\n",
    "This notebook take pre-processed data and applies 14 algorithms to it. Features have to be scaled-continous or dummy encoded.\n",
    "First step is to group the data by adding kmeans of 2, 4, 16, 64 and 128. These are added as additional dummy encoded features.\n",
    "After that 8 algorithms from sklearn package are applied followed by a deep neural network in Keras. \n",
    "\n",
    "Each of the 8 sklearn algorithms go through the following fittings - \n",
    "1. Fitted using defaults sklearn parameters\n",
    "2. Fitted using hand selected paramaters\n",
    "3. Fitted after finding the best paramteres using Bayesian Hyperparameter optimization\n",
    "4. Fitted after calibrating the output probabilities using sigmiod function of sklearn's CalibratedClassifierCV class\n",
    "\n",
    "Last 2 steps are not applied to Keras atm.\n",
    "\n",
    "After the above steps have been carried out, all the algorithms are used to build 4 meta models. \n",
    "1. Stacked classifier using cross-validation and a multi-level Keras preceptron as the meta classfier \n",
    "2. Stacked classifier using cross-validation and a multi-level Keras preceptron as the meta classfier. Original features of the\n",
    "data are also used\n",
    "3. Ensemble classifier with soft voting to minimize the error\n",
    "4. Ensemble classifier with hard voting\n",
    "\n",
    "This notebook is meant as quickstart in the search for an optimal binary classification algorithm. For each of the fittings, multiple parameters are tracked and saved as a json file and a pickle object at the end of the notebook. Predictions are saved as csv files for the positive class for the 4 meta models. I did not re-run the bayesian optimization part before submission cause of time contraint. They were run a day before and the best parameters were recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Models\n",
    "\n",
    "1. SGD Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "2. Random Forest Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "3. Gradient Boosting Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "4. MLP Classifier \n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "5. XGB Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "6. Extratrees Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "7. Decision Tress Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "8. Logistic Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "       - bayesian hyper paramters\n",
    "       - bayesian + probability calibration\n",
    "9. Keras Classifier\n",
    "       - base\n",
    "       - hand tuned hyper parameters\n",
    "10. Stacked CV without features\n",
    "11. Stacked CV with features\n",
    "12. Soft voting ensemble\n",
    "13. Hard voting ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Metrics\n",
    "1. Accuracy score\n",
    "2. f1 score\n",
    "3. Precision score\n",
    "4. Recall score\n",
    "5. Brier Score Loss\n",
    "6. Confusion Matrix\n",
    "7. Hamming Loss\n",
    "8. Jaccard Similarity Score\n",
    "9. Log Loss\n",
    "10. Matthews Coef\n",
    "11. AUC \n",
    "12. ROC\n",
    "13. Time\n",
    "14. Class predictions\n",
    "15. Probability predictions on holdout set\n",
    "16. Probability predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, \\\n",
    "GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from mlxtend.classifier import StackingCVClassifier, EnsembleVoteClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"datasource\")\n",
    "predict = pd.read_csv(\"datasource\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Doing kmeans of:', 2)\n",
      "('Doing kmeans of:', 4)\n",
      "('Doing kmeans of:', 16)\n",
      "('Doing kmeans of:', 64)\n",
      "('Doing kmeans of:', 128)\n"
     ]
    }
   ],
   "source": [
    "train['which'] = 1\n",
    "predict['which'] = 0\n",
    "\n",
    "#data = pd.concat([train.iloc[:numSamples,:],predict.iloc[:numSamples,:]],axis=0)\n",
    "data = pd.concat([train,predict],axis=0)\n",
    "data = shuffle(data)\n",
    "\n",
    "def kmeans(kmeans_num, data):\n",
    "    for k in kmeans_num:\n",
    "        print(\"Doing kmeans of:\",k)\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, init='k-means++', \\\n",
    "                             max_iter=200, batch_size=100, verbose=0, \\\n",
    "                             compute_labels=True, random_state=None, \\\n",
    "                             tol=0.0, max_no_improvement=10, \\\n",
    "                             init_size=None, n_init=3, \\\n",
    "                             reassignment_ratio=0.01)\n",
    "        kmeans.fit(data.iloc[:,:50])\n",
    "        y_predict_km = kmeans.predict(data.iloc[:,:50])\n",
    "\n",
    "        y_predict_km = pd.Series(y_predict_km)\n",
    "        group = \"group\"+str(k)\n",
    "        data[group] = y_predict_km\n",
    "    return data\n",
    "\n",
    "kmeans_num = [2,4,16,64,128]\n",
    "data = kmeans(kmeans_num, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_group = [c for c in data.columns if re.search('^group.*',c) != None]\n",
    "data = pd.get_dummies(data, columns = columns_group)\n",
    "\n",
    "y_train = data[data['which']==1]['target'].values\n",
    "X_train = data[data['which']==1].drop(['target','which','t_id'],axis=1).values\n",
    "\n",
    "t_id = data[data['which']==0]['t_id']\n",
    "predict = data[data['which']==0].drop(['target','which','t_id'],axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_model_metrics = {\n",
    "    \n",
    "    \"accuracy_score\": {\n",
    "        \n",
    "        \"_sgd\":\n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        }        \n",
    "    },\n",
    "    \n",
    "    \"f1_score\": {\n",
    "        \n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"precision_score\": {\n",
    "        \n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"recall_score\": {\n",
    "        \n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"brier_score_loss\": {\n",
    "    \n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        }  \n",
    "    },\n",
    "    \n",
    "    \"confusion_matrix\": \n",
    "     {   \n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "     },\n",
    "    \n",
    "    \"hamming_loss\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        }  \n",
    "    },\n",
    "    \n",
    "    \"jaccard_similarity_score\": \n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"log_loss\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        }  \n",
    "    },\n",
    "    \n",
    "    \"matthews_corrcoef\": \n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"roc_auc_score\": \n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        }  \n",
    "    },\n",
    "    \n",
    "    \"roc_curve\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"calibration_curve\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"predict_proba\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"predict\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"predict_proba_predict\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"predict_predict\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    },\n",
    "    \n",
    "    \"time\":\n",
    "    {\n",
    "        \"_sgd\": \n",
    "        {\n",
    "            \"_sgd\":[],\n",
    "            \"_sgd_base\": [],\n",
    "            \"_sgd_base_sk\": [],\n",
    "            \"_sgd_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_rfc\": \n",
    "        {\n",
    "            \"_rfc\":[],\n",
    "            \"_rfc_base\": [],\n",
    "            \"_rfc_base_sk\": [],\n",
    "            \"_rfc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_gbc\": \n",
    "        {\n",
    "            \"_gbc\":[],\n",
    "            \"_gbc_base\": [],\n",
    "            \"_gbc_base_sk\": [],\n",
    "            \"_gbc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_mlp\": \n",
    "        {\n",
    "            \"_mlp\":[],\n",
    "            \"_mlp_base\": [],\n",
    "            \"_mlp_base_sk\": [],\n",
    "            \"_mlp_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_xgb\": \n",
    "        {\n",
    "            \"_xgb\":[],\n",
    "            \"_xgb_base\": [],\n",
    "            \"_xgb_base_sk\": [],\n",
    "            \"_xgb_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_etc\": \n",
    "        {\n",
    "            \"_etc\":[],\n",
    "            \"_etc_base\": [],\n",
    "            \"_etc_base_sk\": [],\n",
    "            \"_etc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_dtc\": \n",
    "        {\n",
    "            \"_dtc\":[],\n",
    "            \"_dtc_base\": [],\n",
    "            \"_dtc_base_sk\": [],\n",
    "            \"_dtc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_lrc\": \n",
    "        {\n",
    "            \"_lrc\":[],\n",
    "            \"_lrc_base\": [],\n",
    "            \"_lrc_base_sk\": [],\n",
    "            \"_lrc_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_krs\": \n",
    "        {\n",
    "            \"_krs\":[],\n",
    "            \"_krs_base\": [],\n",
    "            \"_krs_base_sk\": [],\n",
    "            \"_krs_base_sk_cal_cv\": []\n",
    "        },\n",
    "        \"_sclf_meta_noF\":\n",
    "        {\n",
    "            \"_sclf_meta_noF\" : []\n",
    "        },\n",
    "        \"_sclf_meta_useF\":\n",
    "        {\n",
    "            \"_sclf_meta_useF\" : []\n",
    "        },\n",
    "        \"_eclf_meta_soft\":\n",
    "        {\n",
    "            \"_eclf_meta_soft\" : []\n",
    "        },\n",
    "        \"_eclf_meta_hard\":\n",
    "        {\n",
    "            \"_eclf_meta_hard\" : []\n",
    "        } \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _compile_model(_model, _model_type, _model_subtype):\n",
    "    start = time.time()\n",
    "    _model.fit(X_train, y_train)\n",
    "    _model_predict = _model.predict(X_test)\n",
    "    _model_predict_proba = _model.predict_proba(X_test)\n",
    "    \n",
    "    _model_predict_predict = _model.predict(predict.values)\n",
    "    _model_predict_proba_predict = _model.predict_proba(predict.values)\n",
    "    \n",
    "    _model_metrics['predict'][_model_type][_model_subtype] = _model_predict\n",
    "    _model_metrics['predict_proba'][_model_type][_model_subtype] = _model_predict_proba\n",
    "    \n",
    "    _model_metrics['predict_predict'][_model_type][_model_subtype] = _model_predict_predict\n",
    "    _model_metrics['predict_proba_predict'][_model_type][_model_subtype] = _model_predict_proba_predict\n",
    "    \n",
    "    _model_metrics['accuracy_score'][_model_type][_model_subtype] = \\\n",
    "    accuracy_score(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['f1_score'][_model_type][_model_subtype] = \\\n",
    "    f1_score(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['precision_score'][_model_type][_model_subtype] = \\\n",
    "    precision_score(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['recall_score'][_model_type][_model_subtype] = \\\n",
    "    recall_score(y_test, _model_predict)\n",
    "\n",
    "    _model_metrics['brier_score_loss'][_model_type][_model_subtype] = \\\n",
    "    brier_score_loss(y_test, _model_predict_proba[:,1])\n",
    "    \n",
    "    # (n_classes,n_classes) array\n",
    "    _model_metrics['confusion_matrix'][_model_type][_model_subtype] = \\\n",
    "    confusion_matrix(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['hamming_loss'][_model_type][_model_subtype] = \\\n",
    "    hamming_loss(y_test, _model_predict) \n",
    "    \n",
    "    _model_metrics['jaccard_similarity_score'][_model_type][_model_subtype] = \\\n",
    "    jaccard_similarity_score(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['log_loss'][_model_type][_model_subtype] = \\\n",
    "    log_loss(y_test, _model_predict_proba)\n",
    "    \n",
    "    _model_metrics['matthews_corrcoef'][_model_type][_model_subtype] = \\\n",
    "    matthews_corrcoef(y_test, _model_predict)\n",
    "    \n",
    "    _model_metrics['roc_auc_score'][_model_type][_model_subtype] = \\\n",
    "    roc_auc_score(y_test, _model_predict_proba[:,1])\n",
    "    \n",
    "    _model_metrics['roc_curve'][_model_type][_model_subtype] = \\\n",
    "    roc_curve(y_test, _model_predict_proba[:,1])  \n",
    "    \n",
    "    _model_metrics['calibration_curve'][_model_type][_model_subtype] = \\\n",
    "    roc_curve(y_test, _model_predict_proba[:,1])\n",
    "    \n",
    "    _elapsed_time = time.time() - start\n",
    "    _model_metrics['time'][_model_type][_model_subtype] = _elapsed_time\n",
    "    _print_metrics(_model_type, _model_subtype)\n",
    "    \n",
    "    if re.search('.*meta.*', _model_type) != None:\n",
    "        predictions_df = _model_predict_proba_predict\n",
    "        predictions_df = np.concatenate([predictions_df,t_id.reshape(predictions_df.shape[0],1)],axis=1)\n",
    "        predictions_df = pd.DataFrame(predictions_df, columns=[\"probability0\",\n",
    "                                                       \"probability\",\n",
    "                                                      \"t_id\"])\n",
    "\n",
    "        predictions = predictions_df[['probability','t_id']]\n",
    "        predictions.to_csv(_model_type+'predict.csv')\n",
    "    \n",
    "def _print_metrics(_model_type, _model_subtype):\n",
    "    _dont_print = ['predict','predict_proba','predict_predict','predict_proba_predict','roc_curve','calibration_curve']\n",
    "    for _score_keys, _name_values in _model_metrics.items():\n",
    "        if _score_keys not in _dont_print:\n",
    "            for _models , _models_metrics in _name_values.items():\n",
    "                if _models == _model_type:\n",
    "                    for _types_models, _types_scores in _models_metrics.items():\n",
    "                        if _types_models == _model_subtype:\n",
    "                            print(_score_keys, \":\", _types_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_sgd = SGDClassifier(loss='log', penalty='l2', alpha=0.0001, \n",
    "              l1_ratio=0.15, fit_intercept=True, \n",
    "              n_iter=5, shuffle=True, verbose=0, \n",
    "              epsilon=0.1, n_jobs=1, random_state=None, \n",
    "              learning_rate='optimal', eta0=0.0, power_t=0.5, \n",
    "              class_weight=None, warm_start=False, average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.12379734912198077)\n",
      "('log_loss', ':', 0.70834222618140197)\n",
      "('precision_score', ':', 0.51714446318156271)\n",
      "('time', ':', 2.6494030952453613)\n",
      "('accuracy_score', ':', 0.50059439352686275)\n",
      "('roc_auc_score', ':', 0.50702608885442002)\n",
      "('jaccard_similarity_score', ':', 0.50059439352686275)\n",
      "('recall_score', ':', 0.070314888413329252)\n",
      "('brier_score_loss', ':', 0.25736899603007346)\n",
      "('matthews_corrcoef', ':', 0.0083338494876857398)\n",
      "('confusion_matrix', ':', array([[12134,   859],\n",
      "       [12164,   920]]))\n",
      "('hamming_loss', ':', 0.49940560647313725)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_sgd, \"_sgd\", \"_sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_sgd_base = SGDClassifier(loss='log', penalty='l2', alpha=0.0001, \n",
    "              l1_ratio=0.15, fit_intercept=True, \n",
    "              n_iter=5, shuffle=True, verbose=0, \n",
    "              epsilon=0.1, n_jobs=-1, random_state=None, \n",
    "              learning_rate='optimal', eta0=0.0, power_t=0.5, \n",
    "              class_weight=None, warm_start=False, average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.029400846388002076)\n",
      "('log_loss', ':', 0.71626194085184813)\n",
      "('precision_score', ':', 0.51428571428571423)\n",
      "('time', ':', 2.4375240802764893)\n",
      "('accuracy_score', ':', 0.49867699505311192)\n",
      "('roc_auc_score', ':', 0.50363547942460285)\n",
      "('jaccard_similarity_score', ':', 0.49867699505311192)\n",
      "('recall_score', ':', 0.015132986854173035)\n",
      "('brier_score_loss', ':', 0.26110368645101706)\n",
      "('matthews_corrcoef', ':', 0.0030703799284770425)\n",
      "('confusion_matrix', ':', array([[12806,   187],\n",
      "       [12886,   198]]))\n",
      "('hamming_loss', ':', 0.50132300494688808)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_sgd_base, \"_sgd\", \"_sgd_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _sgd_base_objective(params):\n",
    "    penalty, alpha, l1_ratio, n_iter, epsilon, eta0, power_t = params\n",
    "\n",
    "    _sgd_base.set_params(penalty=penalty, alpha=alpha,\n",
    "                   l1_ratio=l1_ratio,\n",
    "                  n_iter=n_iter,\n",
    "                  epsilon=epsilon,\n",
    "                  eta0=eta0,\n",
    "                  power_t=power_t)\n",
    "\n",
    "    return -np.mean(cross_val_score(_sgd_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_sgd_base_space  = [('l1','l2'),                          # penalty\n",
    "              (0.00001, 0.01),                         # alpha\n",
    "          (.05,.5),                                  # l1_ratio\n",
    "            (10,25),                      # n_iter\n",
    "                (.01,1),                        # epsilon\n",
    "            (0.001,0.1),                  # eta0\n",
    "                (0.3,1)]                   # power_t    \n",
    "    \n",
    "_sgd_base_res_gp = gp_minimize(_sgd_base_objective, _sgd_base_space, base_estimator=None, \n",
    "            n_calls=150, n_random_starts=3, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fac4c23dcd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZWl5ygzMysLjlBmZlZXfr/PxB9Ab5rphEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac4c23d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_sgd_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_sgd_base_sk = SGDClassifier(loss='log', penalty='l2', alpha=0.01, \n",
    "              l1_ratio=0.15, fit_intercept=True, \n",
    "              n_iter=25, shuffle=True, verbose=0, \n",
    "              epsilon=1, n_jobs=-1, random_state=None, \n",
    "              learning_rate='optimal', eta0=0.0010000000000000009, power_t=0.29999999999999999, \n",
    "              class_weight=None, warm_start=False, average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_sgd_base_sk.penalty, _sgd_base_sk.alpha, _sgd_base_sk.l1_ratio, _sgd_base_sk.n_iter, \\\n",
    "_sgd_base_sk.epsilon, _sgd_base_sk.eta0, _sgd_base_sk.power_t = _sgd_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.55000000000000004)\n",
      "('log_loss', ':', 0.69247600783762187)\n",
      "('precision_score', ':', 0.51366410188378875)\n",
      "('time', ':', 7.016977071762085)\n",
      "('accuracy_score', ':', 0.51405453081259345)\n",
      "('roc_auc_score', ':', 0.5213432188623166)\n",
      "('jaccard_similarity_score', ':', 0.51405453081259345)\n",
      "('recall_score', ':', 0.59186793029654539)\n",
      "('brier_score_loss', ':', 0.24966460065952689)\n",
      "('matthews_corrcoef', ':', 0.027906749452559092)\n",
      "('confusion_matrix', ':', array([[5661, 7332],\n",
      "       [5340, 7744]]))\n",
      "('hamming_loss', ':', 0.48594546918740655)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_sgd_base_sk, \"_sgd\", \"_sgd_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_sgd_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_sgd_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.5203949867071781)\n",
      "('log_loss', ':', 0.69249259648726069)\n",
      "('precision_score', ':', 0.51721274346972668)\n",
      "('time', ':', 12.611415147781372)\n",
      "('accuracy_score', ':', 0.5157418414694942)\n",
      "('roc_auc_score', ':', 0.52123700147267882)\n",
      "('jaccard_similarity_score', ':', 0.5157418414694942)\n",
      "('recall_score', ':', 0.52361663099969424)\n",
      "('brier_score_loss', ':', 0.24967286838798722)\n",
      "('matthews_corrcoef', ':', 0.031432319007219461)\n",
      "('confusion_matrix', ':', array([[6598, 6395],\n",
      "       [6233, 6851]]))\n",
      "('hamming_loss', ':', 0.4842581585305058)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_sgd_base_sk_cal_cv, \"_sgd\", \"_sgd_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_rfc = RandomForestClassifier(n_estimators=10, criterion='gini', \n",
    "                              max_depth=None, min_samples_split=2, \n",
    "                              min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                              max_features='auto', max_leaf_nodes=None, \n",
    "                              min_impurity_split=1e-07, bootstrap=True, oob_score=False, \n",
    "                              n_jobs=-1, random_state=None, verbose=0, warm_start=False, \n",
    "                              class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.43793728945322619)\n",
      "('log_loss', ':', 0.82107221334085512)\n",
      "('precision_score', ':', 0.50347567030784512)\n",
      "('time', ':', 3.891312837600708)\n",
      "('accuracy_score', ':', 0.50093952525213792)\n",
      "('roc_auc_score', ':', 0.50367317345089724)\n",
      "('jaccard_similarity_score', ':', 0.50093952525213792)\n",
      "('recall_score', ':', 0.38749617853867319)\n",
      "('brier_score_loss', ':', 0.27648310771944623)\n",
      "('matthews_corrcoef', ':', 0.0027456725900337937)\n",
      "('confusion_matrix', ':', array([[7993, 5000],\n",
      "       [8014, 5070]]))\n",
      "('hamming_loss', ':', 0.49906047474786208)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_rfc, \"_rfc\", \"_rfc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_rfc_base = RandomForestClassifier(max_depth=None, min_samples_split=2, \n",
    "                             min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                             max_features='auto', max_leaf_nodes=None, \n",
    "                             min_impurity_split=1e-07, bootstrap=True, \n",
    "                             oob_score=False, n_jobs=-1, random_state=None, \n",
    "                             verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.43564442136241666)\n",
      "('log_loss', ':', 0.81445954045056101)\n",
      "('precision_score', ':', 0.50219517062462582)\n",
      "('time', ':', 3.9875729084014893)\n",
      "('accuracy_score', ':', 0.49994247804578745)\n",
      "('roc_auc_score', ':', 0.50416077226918721)\n",
      "('jaccard_similarity_score', ':', 0.49994247804578745)\n",
      "('recall_score', ':', 0.38466829715683276)\n",
      "('brier_score_loss', ':', 0.27594738658588031)\n",
      "('matthews_corrcoef', ':', 0.00071161204757765073)\n",
      "('confusion_matrix', ':', array([[8004, 4989],\n",
      "       [8051, 5033]]))\n",
      "('hamming_loss', ':', 0.50005752195421249)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_rfc_base, \"_rfc\", \"_rfc_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _rfc_base_objective(params):\n",
    "    max_depth, max_features, min_samples_split, min_samples_leaf = params\n",
    "\n",
    "    _rfc_base.set_params(max_depth=max_depth,\n",
    "                   max_features=max_features,\n",
    "                   min_samples_split=min_samples_split,\n",
    "                  min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    return -np.mean(cross_val_score(_rfc_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_rfc_base_space  = [(1, 5),                           # max_depth\n",
    "          (1, 50),                  # max_features\n",
    "          (2, 200),                         # min_samples_split\n",
    "          (1, 100)]                         # min_samples_leaf\n",
    "\n",
    "_rfc_base_res_gp = gp_minimize(_rfc_base_objective, \n",
    "          _rfc_base_space, base_estimator=None, \n",
    "            n_calls=100, n_random_starts=10, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fac4ca002d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAEYCAYAAAD1bUl/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3TgImZlZ3fx/NWl4V0EtWi4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac4c34dc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_rfc_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_rfc_base_sk = RandomForestClassifier(max_depth=4, min_samples_split=153,\n",
    "                             min_samples_leaf=82, min_weight_fraction_leaf=0.0,\n",
    "                             max_features=17, max_leaf_nodes=None,\n",
    "                             min_impurity_split=1e-07, bootstrap=True,\n",
    "                             oob_score=False, n_jobs=-1, random_state=None,\n",
    "                             verbose=0, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.49051001163677221)\n",
      "('log_loss', ':', 0.69262803935829376)\n",
      "('precision_score', ':', 0.51634704739376536)\n",
      "('time', ':', 2.317744016647339)\n",
      "('accuracy_score', ':', 0.51309583157571803)\n",
      "('roc_auc_score', ':', 0.51948178807943124)\n",
      "('jaccard_similarity_score', ':', 0.51309583157571803)\n",
      "('recall_score', ':', 0.46713543258942219)\n",
      "('brier_score_loss', ':', 0.24974046352904469)\n",
      "('matthews_corrcoef', ':', 0.026626691183034266)\n",
      "('confusion_matrix', ':', array([[7268, 5725],\n",
      "       [6972, 6112]]))\n",
      "('hamming_loss', ':', 0.48690416842428191)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_rfc_base_sk, \"_rfc\", \"_rfc_base_sk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_gbc = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                           n_estimators=100, subsample=1.0, \n",
    "                           criterion='friedman_mse', min_samples_split=2, \n",
    "                           min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                           max_depth=3, min_impurity_split=1e-07, init=None, \n",
    "                           random_state=None, max_features=None, verbose=1, \n",
    "                           max_leaf_nodes=None, warm_start=False, presort='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3860            5.38m\n",
      "         2           1.3858            5.27m\n",
      "         3           1.3856            5.20m\n",
      "         4           1.3854            5.16m\n",
      "         5           1.3852            5.13m\n",
      "         6           1.3850            5.06m\n",
      "         7           1.3848            5.00m\n",
      "         8           1.3847            4.89m\n",
      "         9           1.3846            4.84m\n",
      "        10           1.3845            4.75m\n",
      "        20           1.3834            4.14m\n",
      "        30           1.3828            3.46m\n",
      "        40           1.3821            2.89m\n",
      "        50           1.3815            2.38m\n",
      "        60           1.3810            1.88m\n",
      "        70           1.3803            1.40m\n",
      "        80           1.3799           55.83s\n",
      "        90           1.3793           27.79s\n",
      "       100           1.3788            0.00s\n",
      "('f1_score', ':', 0.50833687956980933)\n",
      "('log_loss', ':', 0.69283924398413299)\n",
      "('precision_score', ':', 0.51468860164512342)\n",
      "('time', ':', 284.30304193496704)\n",
      "('accuracy_score', ':', 0.51263565594201788)\n",
      "('roc_auc_score', ':', 0.51887453955111595)\n",
      "('jaccard_similarity_score', ':', 0.51263565594201788)\n",
      "('recall_score', ':', 0.50214001834301436)\n",
      "('brier_score_loss', ':', 0.24984107802088454)\n",
      "('matthews_corrcoef', ':', 0.025350244360650271)\n",
      "('confusion_matrix', ':', array([[6798, 6195],\n",
      "       [6514, 6570]]))\n",
      "('hamming_loss', ':', 0.48736434405798212)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_gbc, \"_gbc\", \"_gbc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_gbc_base = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, \n",
    "                                 n_estimators=100, subsample=1.0, \n",
    "                                 criterion='friedman_mse', min_samples_split=2, \n",
    "                                 min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                 max_depth=3, min_impurity_split=1e-07, init=None, \n",
    "                                 random_state=None, max_features=None, verbose=1, \n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3860            5.88m\n",
      "         2           1.3858            5.82m\n",
      "         3           1.3856            5.76m\n",
      "         4           1.3854            5.73m\n",
      "         5           1.3852            5.70m\n",
      "         6           1.3850            5.67m\n",
      "         7           1.3848            5.59m\n",
      "         8           1.3847            5.48m\n",
      "         9           1.3846            5.41m\n",
      "        10           1.3845            5.31m\n",
      "        20           1.3834            4.61m\n",
      "        30           1.3828            3.86m\n",
      "        40           1.3821            3.23m\n",
      "        50           1.3815            2.66m\n",
      "        60           1.3810            2.11m\n",
      "        70           1.3803            1.57m\n",
      "        80           1.3799            1.04m\n",
      "        90           1.3793           31.11s\n",
      "       100           1.3788            0.00s\n",
      "('f1_score', ':', 0.50845097660027083)\n",
      "('log_loss', ':', 0.69283356021792775)\n",
      "('precision_score', ':', 0.5146817007282124)\n",
      "('time', ':', 316.94162487983704)\n",
      "('accuracy_score', ':', 0.51263565594201788)\n",
      "('roc_auc_score', ':', 0.51889882184520819)\n",
      "('jaccard_similarity_score', ':', 0.51263565594201788)\n",
      "('recall_score', ':', 0.50236930602262309)\n",
      "('brier_score_loss', ':', 0.24983819970084262)\n",
      "('matthews_corrcoef', ':', 0.025348396034087617)\n",
      "('confusion_matrix', ':', array([[6795, 6198],\n",
      "       [6511, 6573]]))\n",
      "('hamming_loss', ':', 0.48736434405798212)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_gbc_base, \"_gbc\", \"_gbc_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _gbc_base_objective(params):\n",
    "    max_depth, learning_rate, max_features, min_samples_split,min_samples_leaf = params\n",
    "\n",
    "    _gbc_base.set_params(max_depth=max_depth,\n",
    "                         learning_rate=learning_rate,\n",
    "                         max_features=max_features,\n",
    "                   min_samples_split=min_samples_split,\n",
    "                        min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "    return -np.mean(cross_val_score(_gbc_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_gbc_base_space  = [(1, 5),                           # max_depth\n",
    "          (10**-5, 10**0, \"log-uniform\"),   # learning_rate\n",
    "          (1, 50),                  # max_features\n",
    "          (2, 100),                         # min_samples_split\n",
    "          (1, 100)]                         # min_samples_leaf\n",
    "\n",
    "_gbc_base_res_gp = gp_minimize(_gbc_base_objective, _gbc_base_space, base_estimator=None, \n",
    "            n_calls=100, n_random_starts=15, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9461653bd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEYCAYAAACKvFuOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+/+0Nh1Ba3UKFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9490c256d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_gbc_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_gbc_base_sk = GradientBoostingClassifier(loss='deviance', learning_rate=0.031122930246332624,\n",
    "                                 n_estimators=200, subsample=1.0,\n",
    "                                 criterion='friedman_mse', min_samples_split=62,\n",
    "                                 min_samples_leaf=14, min_weight_fraction_leaf=0.0,\n",
    "                                 max_depth=2, min_impurity_split=1e-07, init=None,\n",
    "                                 random_state=None, max_features=26, verbose=1,\n",
    "                                 max_leaf_nodes=None, warm_start=False, presort='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_gbc_base_sk.max_depth, _gbc_base_sk.learning_rate, _gbc_base_sk.max_features, \\\n",
    "_gbc_base_sk.min_samples_split, _gbc_base_sk.min_samples_leaf = _gbc_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           55.14s\n",
      "         2           1.3862           48.69s\n",
      "         3           1.3862           48.98s\n",
      "         4           1.3861           47.97s\n",
      "         5           1.3861           48.26s\n",
      "         6           1.3861           47.97s\n",
      "         7           1.3860           47.05s\n",
      "         8           1.3860           46.48s\n",
      "         9           1.3859           46.66s\n",
      "        10           1.3859           46.32s\n",
      "        20           1.3856           44.03s\n",
      "        30           1.3853           41.85s\n",
      "        40           1.3851           39.67s\n",
      "        50           1.3849           37.14s\n",
      "        60           1.3848           34.63s\n",
      "        70           1.3846           32.11s\n",
      "        80           1.3845           29.61s\n",
      "        90           1.3844           27.11s\n",
      "       100           1.3843           24.54s\n",
      "       200           1.3835            0.00s\n",
      "('f1_score', ':', 0.50850610346832004)\n",
      "('log_loss', ':', 0.69248428122836025)\n",
      "('precision_score', ':', 0.51576133951733349)\n",
      "('time', ':', 56.096060037612915)\n",
      "('accuracy_score', ':', 0.51363270314836829)\n",
      "('roc_auc_score', ':', 0.52101275495732324)\n",
      "('jaccard_similarity_score', ':', 0.51363270314836829)\n",
      "('recall_score', ':', 0.5014521553041883)\n",
      "('brier_score_loss', ':', 0.24966862469283368)\n",
      "('matthews_corrcoef', ':', 0.027358662157849288)\n",
      "('confusion_matrix', ':', array([[6833, 6160],\n",
      "       [6523, 6561]]))\n",
      "('hamming_loss', ':', 0.48636729685163171)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_gbc_base_sk, \"_gbc\", \"_gbc_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_gbc_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_gbc_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           35.29s\n",
      "         2           1.3862           34.14s\n",
      "         3           1.3861           34.38s\n",
      "         4           1.3861           34.13s\n",
      "         5           1.3860           33.68s\n",
      "         6           1.3860           33.30s\n",
      "         7           1.3860           32.97s\n",
      "         8           1.3859           32.68s\n",
      "         9           1.3859           32.46s\n",
      "        10           1.3858           32.20s\n",
      "        20           1.3855           29.91s\n",
      "        30           1.3852           28.11s\n",
      "        40           1.3850           26.31s\n",
      "        50           1.3848           24.68s\n",
      "        60           1.3846           22.93s\n",
      "        70           1.3844           21.20s\n",
      "        80           1.3843           19.48s\n",
      "        90           1.3841           17.75s\n",
      "       100           1.3840           16.06s\n",
      "       200           1.3829            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3863           30.37s\n",
      "         2           1.3862           30.44s\n",
      "         3           1.3861           30.75s\n",
      "         4           1.3861           30.08s\n",
      "         5           1.3860           29.44s\n",
      "         6           1.3860           28.96s\n",
      "         7           1.3859           28.97s\n",
      "         8           1.3859           28.82s\n",
      "         9           1.3858           28.60s\n",
      "        10           1.3858           28.49s\n",
      "        20           1.3854           27.19s\n",
      "        30           1.3851           25.49s\n",
      "        40           1.3849           23.97s\n",
      "        50           1.3847           22.34s\n",
      "        60           1.3845           20.79s\n",
      "        70           1.3843           19.12s\n",
      "        80           1.3842           17.59s\n",
      "        90           1.3841           16.06s\n",
      "       100           1.3839           14.54s\n",
      "       200           1.3829            0.00s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           26.78s\n",
      "         2           1.3862           28.80s\n",
      "         3           1.3861           28.51s\n",
      "         4           1.3861           28.83s\n",
      "         5           1.3860           28.48s\n",
      "         6           1.3860           28.51s\n",
      "         7           1.3859           28.32s\n",
      "         8           1.3859           28.29s\n",
      "         9           1.3858           28.14s\n",
      "        10           1.3858           28.16s\n",
      "        20           1.3853           26.89s\n",
      "        30           1.3850           24.95s\n",
      "        40           1.3847           23.54s\n",
      "        50           1.3845           21.92s\n",
      "        60           1.3843           20.41s\n",
      "        70           1.3841           18.88s\n",
      "        80           1.3839           17.34s\n",
      "        90           1.3837           15.85s\n",
      "       100           1.3836           14.35s\n",
      "       200           1.3823            0.00s\n",
      "('f1_score', ':', 0.50740582358200848)\n",
      "('log_loss', ':', 0.6924494414887864)\n",
      "('precision_score', ':', 0.51633831790489759)\n",
      "('time', ':', 110.1550841331482)\n",
      "('accuracy_score', ':', 0.51409287878206844)\n",
      "('roc_auc_score', ':', 0.52190457632537979)\n",
      "('jaccard_similarity_score', ':', 0.51409287878206844)\n",
      "('recall_score', ':', 0.49877713237542037)\n",
      "('brier_score_loss', ':', 0.24965129146967746)\n",
      "('matthews_corrcoef', ':', 0.028306143458789811)\n",
      "('confusion_matrix', ':', array([[6880, 6113],\n",
      "       [6558, 6526]]))\n",
      "('hamming_loss', ':', 0.4859071212179315)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_gbc_base_sk_cal_cv, \"_gbc\", \"_gbc_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# MLP Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_mlp = MLPClassifier(hidden_layer_sizes=(100, ), activation='relu', solver='adam', \n",
    "                     alpha=0.0001, batch_size='auto', learning_rate='constant', \n",
    "                     learning_rate_init=0.001, power_t=0.5, max_iter=200, \n",
    "                     shuffle=True, random_state=None, tol=0.0001, verbose=True, \n",
    "                     warm_start=False, momentum=0.9, nesterovs_momentum=True, \n",
    "                     early_stopping=True, validation_fraction=0.1, beta_1=0.9, \n",
    "                     beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69443926\n",
      "Validation score: 0.511200\n",
      "Iteration 2, loss = 0.69274143\n",
      "Validation score: 0.505380\n",
      "Iteration 3, loss = 0.69229589\n",
      "Validation score: 0.511944\n",
      "Iteration 4, loss = 0.69209999\n",
      "Validation score: 0.510455\n",
      "Iteration 5, loss = 0.69168177\n",
      "Validation score: 0.511538\n",
      "Iteration 6, loss = 0.69141488\n",
      "Validation score: 0.506463\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "('f1_score', ':', 0.54905292972207465)\n",
      "('log_loss', ':', 0.69278772638319264)\n",
      "('precision_score', ':', 0.5114438361585647)\n",
      "('time', ':', 76.42213892936707)\n",
      "('accuracy_score', ':', 0.51156191279671737)\n",
      "('roc_auc_score', ':', 0.51839234366090836)\n",
      "('jaccard_similarity_score', ':', 0.51156191279671737)\n",
      "('recall_score', ':', 0.59263222256190773)\n",
      "('brier_score_loss', ':', 0.24981996691972239)\n",
      "('matthews_corrcoef', ':', 0.022860826024548232)\n",
      "('confusion_matrix', ':', array([[5586, 7407],\n",
      "       [5330, 7754]]))\n",
      "('hamming_loss', ':', 0.48843808720328258)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_mlp, \"_mlp\", \"_mlp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_mlp_base = MLPClassifier(hidden_layer_sizes=(220,100,75,25, ), activation='relu',\n",
    "                     alpha=0.001, batch_size='auto', \n",
    "                    learning_rate='adaptive', learning_rate_init=0.001, \n",
    "                    power_t=0.5, max_iter=200, shuffle=True, random_state=None, \n",
    "                    tol=0.0001, verbose=True, warm_start=True, momentum=0.9, \n",
    "                    nesterovs_momentum=True, early_stopping=True, validation_fraction=0.1, \n",
    "                    beta_1=0.9, beta_2=0.999, epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69424340\n",
      "Validation score: 0.508831\n",
      "Iteration 2, loss = 0.69364546\n",
      "Validation score: 0.504771\n",
      "Iteration 3, loss = 0.69316666\n",
      "Validation score: 0.509914\n",
      "Iteration 4, loss = 0.69287854\n",
      "Validation score: 0.507004\n",
      "Iteration 5, loss = 0.69263824\n",
      "Validation score: 0.509305\n",
      "Iteration 6, loss = 0.69248541\n",
      "Validation score: 0.508628\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "('f1_score', ':', 0.49005613472333598)\n",
      "('log_loss', ':', 0.69296070723091197)\n",
      "('precision_score', ':', 0.51543522267206476)\n",
      "('time', ':', 44.12280321121216)\n",
      "('accuracy_score', ':', 0.5122905242167427)\n",
      "('roc_auc_score', ':', 0.51762519846128374)\n",
      "('jaccard_similarity_score', ':', 0.5122905242167427)\n",
      "('recall_score', ':', 0.46705900336288597)\n",
      "('brier_score_loss', ':', 0.24990607617216304)\n",
      "('matthews_corrcoef', ':', 0.025000718447478587)\n",
      "('confusion_matrix', ':', array([[7248, 5745],\n",
      "       [6973, 6111]]))\n",
      "('hamming_loss', ':', 0.4877094757832573)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_mlp_base, \"_mlp\", \"_mlp_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_mlp_base_cal_cv = CalibratedClassifierCV(base_estimator=_mlp_base, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.69447620\n",
      "Validation score: 0.514312\n",
      "Iteration 2, loss = 0.69388919\n",
      "Validation score: 0.500812\n",
      "Iteration 3, loss = 0.69360388\n",
      "Validation score: 0.509338\n",
      "Iteration 4, loss = 0.69312564\n",
      "Validation score: 0.516545\n",
      "Iteration 5, loss = 0.69285441\n",
      "Validation score: 0.506192\n",
      "Iteration 6, loss = 0.69254989\n",
      "Validation score: 0.512180\n",
      "Iteration 7, loss = 0.69237708\n",
      "Validation score: 0.514819\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69437601\n",
      "Validation score: 0.507816\n",
      "Iteration 2, loss = 0.69386360\n",
      "Validation score: 0.506699\n",
      "Iteration 3, loss = 0.69317708\n",
      "Validation score: 0.501827\n",
      "Iteration 4, loss = 0.69287542\n",
      "Validation score: 0.503959\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.69441256\n",
      "Validation score: 0.494722\n",
      "Iteration 2, loss = 0.69359129\n",
      "Validation score: 0.513601\n",
      "Iteration 3, loss = 0.69316353\n",
      "Validation score: 0.508425\n",
      "Iteration 4, loss = 0.69266832\n",
      "Validation score: 0.517560\n",
      "Iteration 5, loss = 0.69236921\n",
      "Validation score: 0.511977\n",
      "Iteration 6, loss = 0.69208344\n",
      "Validation score: 0.513398\n",
      "Iteration 7, loss = 0.69183478\n",
      "Validation score: 0.501320\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "('f1_score', ':', 0.52359037677255205)\n",
      "('log_loss', ':', 0.69269748733032466)\n",
      "('precision_score', ':', 0.51286373964670529)\n",
      "('time', ':', 101.90419697761536)\n",
      "('accuracy_score', ':', 0.51171530467461745)\n",
      "('roc_auc_score', ':', 0.51836296137917592)\n",
      "('jaccard_similarity_score', ':', 0.51171530467461745)\n",
      "('recall_score', ':', 0.5347752980739835)\n",
      "('brier_score_loss', ':', 0.24977521360254631)\n",
      "('matthews_corrcoef', ':', 0.023294009445502046)\n",
      "('confusion_matrix', ':', array([[6347, 6646],\n",
      "       [6087, 6997]]))\n",
      "('hamming_loss', ':', 0.48828469532538255)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_mlp_base_cal_cv, \"_mlp\", \"_mlp_base_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This one does not work\n",
    "def _mlp_base_objective(params):\n",
    "    activation, alpha, learning_rate_init, max_iter, momentum, learning_rate = params\n",
    "\n",
    "    _mlp_base.set_params(activation=activation,\n",
    "                   alpha=alpha, \n",
    "                   learning_rate_init=learning_rate_init,\n",
    "                   max_iter=max_iter,momentum=momentum,learning_rate=learning_rate)\n",
    "\n",
    "    return -np.mean(cross_val_score(_mlp_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    " \n",
    "_mlp_base_space = [                          \n",
    "              (\"relu\", \"tanh\"),                         # activation \n",
    "                (.05,.001),                    # alpha\n",
    "                  (0.01,0.001),                             # learning_rate_init\n",
    "                   (10,200),                          # max_iter\n",
    "                     (0.65,1),                 # momentum\n",
    "                        (0.0001,0.1)         # learning rate\n",
    "            ]\n",
    "_mlp_base_res_gp = gp_minimize(_mlp_base_objective, \n",
    "            _mlp_base_space, base_estimator=None, \n",
    "            n_calls=10, n_random_starts=10, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# XGB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_xgb = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, \n",
    "                     silent=False, objective='binary:logistic', nthread=-1, \n",
    "                     gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "                     colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, reg_lambda=1, \n",
    "                     scale_pos_weight=1, base_score=0.5, seed=0, missing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51062516872999342)\n",
      "('log_loss', ':', 0.69264608884340473)\n",
      "('precision_score', ':', 0.51537563254184504)\n",
      "('time', ':', 9.930334091186523)\n",
      "('accuracy_score', ':', 0.51340261533151821)\n",
      "('roc_auc_score', ':', 0.51980941669717839)\n",
      "('jaccard_similarity_score', ':', 0.51340261533151821)\n",
      "('recall_score', ':', 0.50596147966982574)\n",
      "('brier_score_loss', ':', 0.2497474741618862)\n",
      "('matthews_corrcoef', ':', 0.026860141216428091)\n",
      "('confusion_matrix', ':', array([[6768, 6225],\n",
      "       [6464, 6620]]))\n",
      "('hamming_loss', ':', 0.48659738466848179)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_xgb, \"_xgb\", \"_xgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_xgb_base = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, \n",
    "                     silent=False, objective='binary:logistic', nthread=-1, \n",
    "                     gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, \n",
    "                     colsample_bytree=1, colsample_bylevel=1, reg_alpha=0, \n",
    "                     reg_lambda=1, scale_pos_weight=1, base_score=0.5, seed=0, \n",
    "                     missing=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51062516872999342)\n",
      "('log_loss', ':', 0.69264608884340473)\n",
      "('precision_score', ':', 0.51537563254184504)\n",
      "('time', ':', 9.641983985900879)\n",
      "('accuracy_score', ':', 0.51340261533151821)\n",
      "('roc_auc_score', ':', 0.51980941669717839)\n",
      "('jaccard_similarity_score', ':', 0.51340261533151821)\n",
      "('recall_score', ':', 0.50596147966982574)\n",
      "('brier_score_loss', ':', 0.2497474741618862)\n",
      "('matthews_corrcoef', ':', 0.026860141216428091)\n",
      "('confusion_matrix', ':', array([[6768, 6225],\n",
      "       [6464, 6620]]))\n",
      "('hamming_loss', ':', 0.48659738466848179)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_xgb_base, \"_xgb\", \"_xgb_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization (number of iteration are set to minimum cause of cost complexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _xgb_base_objective(params):\n",
    "    max_depth, learning_rate, colsample_bylevel,reg_lambda,n_estimators = params\n",
    "\n",
    "    _xgb_base.set_params(max_depth=max_depth,\n",
    "                   learning_rate=learning_rate,\n",
    "                   #max_features=max_features,\n",
    "                   colsample_bylevel=colsample_bylevel,\n",
    "                  reg_lambda=reg_lambda,\n",
    "                        n_estimators=n_estimators)\n",
    "\n",
    "    return -np.mean(cross_val_score(_xgb_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_xgb_base_space  = [(2, 6),                           # max_depth\n",
    "          (10**-5, 10**0),   # learning_rate\n",
    "          (.2, .4),                         # colsample_bylevel\n",
    "          (1, 3),                     # reg_lambda\n",
    "            (100,250)]                         # n_estimators\n",
    "\n",
    "_xgb_base_res_gp = gp_minimize(_xgb_base_objective,_xgb_base_space, base_estimator=None, \n",
    "            n_calls=20, n_random_starts=4, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_xgb_base_sk = XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.01, max_delta_step=0, max_depth=5,\n",
    "       min_child_weight=1, missing=None, n_estimators=200, nthread=-1,\n",
    "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_xgb_base_sk.max_depth, _xgb_base_sk.learning_rate, _xgb_base_sk.colsample_bylevel, \\\n",
    "_xgb_base_sk.reg_lambda, _xgb_base_sk.n_estimators = _xgb_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.50350959288722508)\n",
      "('log_loss', ':', 0.6925889871788522)\n",
      "('precision_score', ':', 0.51401273885350318)\n",
      "('time', ':', 18.575144052505493)\n",
      "('accuracy_score', ':', 0.51175365264409245)\n",
      "('roc_auc_score', ':', 0.51873019578329016)\n",
      "('jaccard_similarity_score', ':', 0.51175365264409245)\n",
      "('recall_score', ':', 0.49342708651788442)\n",
      "('brier_score_loss', ':', 0.2497211316696234)\n",
      "('matthews_corrcoef', ':', 0.023651448904398728)\n",
      "('confusion_matrix', ':', array([[6889, 6104],\n",
      "       [6628, 6456]]))\n",
      "('hamming_loss', ':', 0.4882463473559075)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_xgb_base_sk, \"_xgb\", \"_xgb_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_xgb_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_xgb_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.50076756543987411)\n",
      "('log_loss', ':', 0.6926099004211711)\n",
      "('precision_score', ':', 0.51627302978654332)\n",
      "('time', ':', 41.3513388633728)\n",
      "('accuracy_score', ':', 0.51363270314836829)\n",
      "('roc_auc_score', ':', 0.52051721204063905)\n",
      "('jaccard_similarity_score', ':', 0.51363270314836829)\n",
      "('recall_score', ':', 0.48616630999694282)\n",
      "('brier_score_loss', ':', 0.24973147055899481)\n",
      "('matthews_corrcoef', ':', 0.027499276050210839)\n",
      "('confusion_matrix', ':', array([[7033, 5960],\n",
      "       [6723, 6361]]))\n",
      "('hamming_loss', ':', 0.48636729685163171)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_xgb_base_sk_cal_cv, \"_xgb\", \"_xgb_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_etc = ExtraTreesClassifier(n_estimators=10, criterion='gini', \n",
    "                            max_depth=None, min_samples_split=2, \n",
    "                            min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "                            max_features='auto', max_leaf_nodes=None, \n",
    "                            min_impurity_split=1e-07, bootstrap=False, \n",
    "                            oob_score=False, n_jobs=-1, random_state=None, \n",
    "                            verbose=1, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of  10 | elapsed:    1.2s remaining:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    0.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.4404602853079343)\n",
      "('log_loss', ':', 0.79582315812964355)\n",
      "('precision_score', ':', 0.50499061172052573)\n",
      "('time', ':', 3.6685009002685547)\n",
      "('accuracy_score', ':', 0.50212831230586341)\n",
      "('roc_auc_score', ':', 0.50403677256970403)\n",
      "('jaccard_similarity_score', ':', 0.50212831230586341)\n",
      "('recall_score', ':', 0.39055334760012228)\n",
      "('brier_score_loss', ':', 0.27630478966138738)\n",
      "('matthews_corrcoef', ':', 0.0051692932295796567)\n",
      "('confusion_matrix', ':', array([[7984, 5009],\n",
      "       [7974, 5110]]))\n",
      "('hamming_loss', ':', 0.49787168769413659)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   2 out of  10 | elapsed:    0.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_etc, \"_etc\", \"_etc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_etc_base = ExtraTreesClassifier(n_estimators=100,\n",
    "                            max_depth=6, min_samples_split=2, \n",
    "                            min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                            max_features='auto', max_leaf_nodes=None, \n",
    "                            min_impurity_split=1e-07, bootstrap=False, \n",
    "                            oob_score=False, n_jobs=-1, random_state=None, \n",
    "                            verbose=0, warm_start=True, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.52315706035556575)\n",
      "('log_loss', ':', 0.69267258092679329)\n",
      "('precision_score', ':', 0.51681706316652998)\n",
      "('time', ':', 3.6935548782348633)\n",
      "('accuracy_score', ':', 0.51555010162211912)\n",
      "('roc_auc_score', ':', 0.52070364394175706)\n",
      "('jaccard_similarity_score', ':', 0.51555010162211912)\n",
      "('recall_score', ':', 0.52965453989605626)\n",
      "('brier_score_loss', ':', 0.24976275632780789)\n",
      "('matthews_corrcoef', ':', 0.031013753935904272)\n",
      "('confusion_matrix', ':', array([[6514, 6479],\n",
      "       [6154, 6930]]))\n",
      "('hamming_loss', ':', 0.48444989837788088)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_etc_base, \"_etc\", \"_etc_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 63.6701\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 12.5972\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 18.0051\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 45.9290\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 14.2253\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 29.8600\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.3080\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 57.8648\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.4359\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.0195\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.2396\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.6509\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 101.3201\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2096\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 101.7715\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.1547\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8897\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.4648\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.7314\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.9291\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 72.8617\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.3777\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.8922\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.9684\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.6605\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 17.5089\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 22.1496\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.4904\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 30.2324\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.7996\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 54.0751\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 39.4947\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 85.9995\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 47.7308\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 21.5854\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 9.9266\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.0054\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 25.4350\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.7183\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.1525\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 27.9047\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 42.7205\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 20.6552\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 11.6631\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.0203\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7002\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 45.9775\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 81.3147\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 10.6994\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.6700\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n"
     ]
    }
   ],
   "source": [
    "def _etc_base_objective(params):\n",
    "    max_depth, bootstrap, max_features, min_samples_split, \\\n",
    "    min_samples_leaf, n_estimators = params\n",
    "\n",
    "    _etc_base.set_params(max_depth=max_depth,\n",
    "                   bootstrap=bootstrap,max_features=max_features,\n",
    "                   min_samples_leaf=min_samples_leaf,\n",
    "                   min_samples_split=min_samples_split,\n",
    "                  n_estimators=n_estimators)\n",
    "\n",
    "    return -np.mean(cross_val_score(_etc_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_etc_base_space  = [(1, 5),                           # max_depth\n",
    "          ('True', 'False'),   # bootstrap\n",
    "          (1, 50),                  # max_features\n",
    "          (2, 100),                         # min_samples_split\n",
    "          (1, 100),                         # min_samples_leaf\n",
    "             (100,400)]                         # n_estimators\n",
    "                           \n",
    "_etc_base_res_gp = gp_minimize(_etc_base_objective, \n",
    "              _etc_base_space, base_estimator=None, \n",
    "            n_calls=50, n_random_starts=5, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f64b42c9d50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEYCAYAAAD4czk4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64b4498310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_etc_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_etc_base_sk = ExtraTreesClassifier(n_estimators=326, criterion='entropy',\n",
    "                            max_depth=5, min_samples_split=2,\n",
    "                            min_samples_leaf=100, min_weight_fraction_leaf=0.0,\n",
    "                            max_features=50, max_leaf_nodes=None,\n",
    "                            min_impurity_split=1e-07, bootstrap=True,\n",
    "                            oob_score=False, n_jobs=-1, random_state=None,\n",
    "                            verbose=1, warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_etc_base_sk.max_depth,_etc_base_sk.bootstrap,_etc_base_sk.max_features, \\\n",
    "_etc_base_sk.min_samples_split,_etc_base_sk.min_samples_leaf, \\\n",
    "_etc_base_sk.n_estimators = _etc_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    5.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51956074124914198)\n",
      "('log_loss', ':', 0.69258359248342383)\n",
      "('precision_score', ':', 0.51841424440724393)\n",
      "('time', ':', 10.148895025253296)\n",
      "('accuracy_score', ':', 0.5168155846147946)\n",
      "('roc_auc_score', ':', 0.52148150088012724)\n",
      "('jaccard_similarity_score', ':', 0.5168155846147946)\n",
      "('recall_score', ':', 0.52071232039131765)\n",
      "('brier_score_loss', ':', 0.24971829601736048)\n",
      "('matthews_corrcoef', ':', 0.033604731545535553)\n",
      "('confusion_matrix', ':', array([[6664, 6329],\n",
      "       [6271, 6813]]))\n",
      "('hamming_loss', ':', 0.48318441538520535)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_etc_base_sk, \"_etc\", \"_etc_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_etc_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_etc_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    4.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    4.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.5221379833206975)\n",
      "('log_loss', ':', 0.69244403883619932)\n",
      "('precision_score', ':', 0.51797533092659442)\n",
      "('time', ':', 26.22573208808899)\n",
      "('accuracy_score', ':', 0.51658549679794452)\n",
      "('roc_auc_score', ':', 0.52179425306333971)\n",
      "('jaccard_similarity_score', ':', 0.51658549679794452)\n",
      "('recall_score', ':', 0.5263680831549985)\n",
      "('brier_score_loss', ':', 0.24964865552864746)\n",
      "('matthews_corrcoef', ':', 0.03310873438825726)\n",
      "('confusion_matrix', ':', array([[6584, 6409],\n",
      "       [6197, 6887]]))\n",
      "('hamming_loss', ':', 0.48341450320205548)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_etc_base_sk_cal_cv, \"_etc\", \"_etc_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_dtc = DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                              max_depth=None, min_samples_split=2, \n",
    "                              min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                              max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                              min_impurity_split=1e-07, class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.5000767224182906)\n",
      "('log_loss', ':', 17.260778999826513)\n",
      "('precision_score', ':', 0.50200246457178066)\n",
      "('time', ':', 40.29994297027588)\n",
      "('accuracy_score', ':', 0.50024926180158757)\n",
      "('roc_auc_score', ':', 0.50025655820175297)\n",
      "('jaccard_similarity_score', ':', 0.50024926180158757)\n",
      "('recall_score', ':', 0.49816569856313053)\n",
      "('brier_score_loss', ':', 0.49975073819841237)\n",
      "('matthews_corrcoef', ':', 0.00051311776175756241)\n",
      "('confusion_matrix', ':', array([[6527, 6466],\n",
      "       [6566, 6518]]))\n",
      "('hamming_loss', ':', 0.49975073819841237)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_dtc, \"_dtc\", \"_dtc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_dtc_base = DecisionTreeClassifier(splitter='best', \n",
    "                              max_depth=None, min_samples_split=2, \n",
    "                              min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                              max_features=None, random_state=None, \n",
    "                              max_leaf_nodes=None, min_impurity_split=1e-07, \n",
    "                              class_weight=None, presort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.49819494584837543)\n",
      "('log_loss', ':', 17.305811725884993)\n",
      "('precision_score', ':', 0.50069476609541452)\n",
      "('time', ':', 40.67822790145874)\n",
      "('accuracy_score', ':', 0.49894543083943704)\n",
      "('roc_auc_score', ':', 0.49895672605781682)\n",
      "('jaccard_similarity_score', ':', 0.49894543083943704)\n",
      "('recall_score', ':', 0.49571996331397128)\n",
      "('brier_score_loss', ':', 0.5010545691605629)\n",
      "('matthews_corrcoef', ':', -0.0020865789990979619)\n",
      "('confusion_matrix', ':', array([[6525, 6468],\n",
      "       [6598, 6486]]))\n",
      "('hamming_loss', ':', 0.5010545691605629)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_dtc_base, \"_dtc\", \"_dtc_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 5.9758\n",
      "Function value obtained: 0.7018\n",
      "Current minimum: 0.7018\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 4.8530\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6930\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 5.2146\n",
      "Function value obtained: 0.6956\n",
      "Current minimum: 0.6930\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 4.4938\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 4.8273\n",
      "Function value obtained: 0.6970\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 4.8389\n",
      "Function value obtained: 0.6938\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 6.0518\n",
      "Function value obtained: 0.6981\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 7.2099\n",
      "Function value obtained: 0.6944\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9818\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8749\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8559\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9856\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5185\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7961\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8038\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9382\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.8524\n",
      "Function value obtained: 0.6954\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4757\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.6526\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9095\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7507\n",
      "Function value obtained: 0.6934\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2982\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4802\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7977\n",
      "Function value obtained: 0.6961\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2085\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.7864\n",
      "Function value obtained: 0.7075\n",
      "Current minimum: 0.6928\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3251\n",
      "Function value obtained: 0.6927\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0110\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1471\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2624\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9792\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9612\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1426\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5626\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3073\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9453\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1657\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7380\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2790\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9721\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5920\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9782\n",
      "Function value obtained: 0.6964\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3700\n",
      "Function value obtained: 0.6940\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4059\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9185\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4618\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5618\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9229\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3055\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0001\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1441\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1174\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.3790\n",
      "Function value obtained: 0.6951\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1834\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7617\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0287\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8140\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2152\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.1192\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2499\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n",
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0806\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.7238\n",
      "Function value obtained: 0.6954\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2936\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n",
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2366\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0281\n",
      "Function value obtained: 0.6944\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0192\n",
      "Function value obtained: 0.6986\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n",
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5260\n",
      "Function value obtained: 0.6937\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n",
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4386\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n",
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2458\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n",
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3313\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4182\n",
      "Function value obtained: 0.6928\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n",
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3882\n",
      "Function value obtained: 0.6932\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n",
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2281\n",
      "Function value obtained: 0.6929\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n",
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 6.9644\n",
      "Function value obtained: 0.6930\n",
      "Current minimum: 0.6927\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n",
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.6212\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6927\n"
     ]
    }
   ],
   "source": [
    "def _dtc_base_objective(params):\n",
    "    max_depth, max_features,min_weight_fraction_leaf,max_leaf_nodes, \\\n",
    "    min_samples_split = params\n",
    "\n",
    "    _dtc_base.set_params(max_depth=max_depth,\n",
    "                   max_features=max_features,\n",
    "                   min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "                   max_leaf_nodes=max_leaf_nodes,\n",
    "                   min_samples_split=min_samples_split)\n",
    "\n",
    "    return -np.mean(cross_val_score(_dtc_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_dtc_base_space  = [(1, 5),                           # max_depth\n",
    "          (1, 50),                  # max_features\n",
    "          (0, .25),                         # min_weight_fraction_leaf\n",
    "          (2, 150),                         # max_leaf_nodes\n",
    "            (2,50)]                        #min_samples_split\n",
    "\n",
    "_dtc_base_res_gp = gp_minimize(_dtc_base_objective, _dtc_base_space, base_estimator=None, \n",
    "            n_calls=75, n_random_starts=8, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f64ba2992d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEYCAYAAACUdWs9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMk4qZmbWMv8fRdQ+shIl9x8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64b5db0d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_dtc_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_dtc_base_sk = DecisionTreeClassifier(class_weight=None, criterion='gini',\n",
    "                              max_depth=1, max_features=50, max_leaf_nodes=58,\n",
    "                              min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                              presort=False, random_state=None, splitter='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_dtc_base_sk.max_depth,_dtc_base_sk.max_features, \\\n",
    "_dtc_base_sk.min_weight_fraction_leaf,_dtc_base_sk.max_leaf_nodes, \\\n",
    "_dtc_base_sk.min_samples_split = _dtc_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.37697659709044906)\n",
      "('log_loss', ':', 0.69290089997287041)\n",
      "('precision_score', ':', 0.51867719908957022)\n",
      "('time', ':', 2.103992223739624)\n",
      "('accuracy_score', ':', 0.5089542508724163)\n",
      "('roc_auc_score', ':', 0.51173592449881822)\n",
      "('jaccard_similarity_score', ':', 0.5089542508724163)\n",
      "('recall_score', ':', 0.29608682360134514)\n",
      "('brier_score_loss', ':', 0.24987683294825727)\n",
      "('matthews_corrcoef', ':', 0.021455156201374555)\n",
      "('confusion_matrix', ':', array([[9398, 3595],\n",
      "       [9210, 3874]]))\n",
      "('hamming_loss', ':', 0.4910457491275837)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_dtc_base_sk, \"_dtc\", \"_dtc_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_dtc_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_dtc_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.46959218743451109)\n",
      "('log_loss', ':', 0.69271220843346282)\n",
      "('precision_score', ':', 0.51990719257540607)\n",
      "('time', ':', 5.092869997024536)\n",
      "('accuracy_score', ':', 0.5147064462936688)\n",
      "('roc_auc_score', ':', 0.5198363195731549)\n",
      "('jaccard_similarity_score', ':', 0.5147064462936688)\n",
      "('recall_score', ':', 0.4281565270559462)\n",
      "('brier_score_loss', ':', 0.24978255440505226)\n",
      "('matthews_corrcoef', ':', 0.030481719302182499)\n",
      "('confusion_matrix', ':', array([[7820, 5173],\n",
      "       [7482, 5602]]))\n",
      "('hamming_loss', ':', 0.48529355370633126)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_dtc_base_sk_cal_cv, \"_dtc\", \"_dtc_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_lrc = LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
    "                          C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                          class_weight=None, random_state=None, solver='liblinear', \n",
    "                          max_iter=100, multi_class='ovr', verbose=0, warm_start=False, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51658605324294471)\n",
      "('log_loss', ':', 0.69313698274688396)\n",
      "('precision_score', ':', 0.51484096257496392)\n",
      "('time', ':', 9.899363994598389)\n",
      "('accuracy_score', ':', 0.51324922345361812)\n",
      "('roc_auc_score', ':', 0.51632533690565396)\n",
      "('jaccard_similarity_score', ':', 0.51324922345361812)\n",
      "('recall_score', ':', 0.51834301436869457)\n",
      "('brier_score_loss', ':', 0.24999325306476919)\n",
      "('matthews_corrcoef', ':', 0.026464018109433822)\n",
      "('confusion_matrix', ':', array([[6602, 6391],\n",
      "       [6302, 6782]]))\n",
      "('hamming_loss', ':', 0.48675077654638188)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_lrc, \"_lrc\", \"_lrc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_lrc_base = LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
    "                           C=1.0, fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight=None, random_state=None, \n",
    "                           solver='liblinear', max_iter=100, \n",
    "                           multi_class='ovr', verbose=0, \n",
    "                           warm_start=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51658605324294471)\n",
      "('log_loss', ':', 0.69313698274688396)\n",
      "('precision_score', ':', 0.51484096257496392)\n",
      "('time', ':', 10.069700002670288)\n",
      "('accuracy_score', ':', 0.51324922345361812)\n",
      "('roc_auc_score', ':', 0.51632533690565396)\n",
      "('jaccard_similarity_score', ':', 0.51324922345361812)\n",
      "('recall_score', ':', 0.51834301436869457)\n",
      "('brier_score_loss', ':', 0.24999325306476919)\n",
      "('matthews_corrcoef', ':', 0.026464018109433822)\n",
      "('confusion_matrix', ':', array([[6602, 6391],\n",
      "       [6302, 6782]]))\n",
      "('hamming_loss', ':', 0.48675077654638188)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_lrc_base, \"_lrc\", \"_lrc_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Bayesian Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 4.5916\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 5.1844\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 4.6750\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 4.6572\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 4.5521\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 6 started. Evaluating function at random point.\n",
      "Iteration No: 6 ended. Evaluation done at random point.\n",
      "Time taken: 5.4564\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 7 started. Evaluating function at random point.\n",
      "Iteration No: 7 ended. Evaluation done at random point.\n",
      "Time taken: 5.1300\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 8 started. Evaluating function at random point.\n",
      "Iteration No: 8 ended. Evaluation done at random point.\n",
      "Time taken: 5.4650\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 9 started. Evaluating function at random point.\n",
      "Iteration No: 9 ended. Evaluation done at random point.\n",
      "Time taken: 4.5977\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 10 started. Evaluating function at random point.\n",
      "Iteration No: 10 ended. Evaluation done at random point.\n",
      "Time taken: 7.1151\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 11 started. Searching for the next optimal point.\n",
      "Iteration No: 11 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3257\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 12 started. Searching for the next optimal point.\n",
      "Iteration No: 12 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8105\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 13 started. Searching for the next optimal point.\n",
      "Iteration No: 13 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.0997\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 14 started. Searching for the next optimal point.\n",
      "Iteration No: 14 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2537\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 15 started. Searching for the next optimal point.\n",
      "Iteration No: 15 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2902\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 16 started. Searching for the next optimal point.\n",
      "Iteration No: 16 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2339\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 17 started. Searching for the next optimal point.\n",
      "Iteration No: 17 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2389\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 18 started. Searching for the next optimal point.\n",
      "Iteration No: 18 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3374\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 19 started. Searching for the next optimal point.\n",
      "Iteration No: 19 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3058\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 20 started. Searching for the next optimal point.\n",
      "Iteration No: 20 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4609\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 21 started. Searching for the next optimal point.\n",
      "Iteration No: 21 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2437\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 22 started. Searching for the next optimal point.\n",
      "Iteration No: 22 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2022\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 23 started. Searching for the next optimal point.\n",
      "Iteration No: 23 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2481\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 24 started. Searching for the next optimal point.\n",
      "Iteration No: 24 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7532\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 25 started. Searching for the next optimal point.\n",
      "Iteration No: 25 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0356\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 26 started. Searching for the next optimal point.\n",
      "Iteration No: 26 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2334\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 27 started. Searching for the next optimal point.\n",
      "Iteration No: 27 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8209\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 28 started. Searching for the next optimal point.\n",
      "Iteration No: 28 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9432\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 29 started. Searching for the next optimal point.\n",
      "Iteration No: 29 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3479\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 30 started. Searching for the next optimal point.\n",
      "Iteration No: 30 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7675\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 31 started. Searching for the next optimal point.\n",
      "Iteration No: 31 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2863\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 32 started. Searching for the next optimal point.\n",
      "Iteration No: 32 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9779\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 33 started. Searching for the next optimal point.\n",
      "Iteration No: 33 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0129\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 34 started. Searching for the next optimal point.\n",
      "Iteration No: 34 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7208\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 35 started. Searching for the next optimal point.\n",
      "Iteration No: 35 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0198\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 36 started. Searching for the next optimal point.\n",
      "Iteration No: 36 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8212\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 37 started. Searching for the next optimal point.\n",
      "Iteration No: 37 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8991\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 38 started. Searching for the next optimal point.\n",
      "Iteration No: 38 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8036\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 39 started. Searching for the next optimal point.\n",
      "Iteration No: 39 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0510\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 40 started. Searching for the next optimal point.\n",
      "Iteration No: 40 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3175\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 41 started. Searching for the next optimal point.\n",
      "Iteration No: 41 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2655\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 42 started. Searching for the next optimal point.\n",
      "Iteration No: 42 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7971\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 43 started. Searching for the next optimal point.\n",
      "Iteration No: 43 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3064\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 44 started. Searching for the next optimal point.\n",
      "Iteration No: 44 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3210\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 45 started. Searching for the next optimal point.\n",
      "Iteration No: 45 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2589\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 46 started. Searching for the next optimal point.\n",
      "Iteration No: 46 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2827\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 47 started. Searching for the next optimal point.\n",
      "Iteration No: 47 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2576\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 48 started. Searching for the next optimal point.\n",
      "Iteration No: 48 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8597\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 49 started. Searching for the next optimal point.\n",
      "Iteration No: 49 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7751\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 50 started. Searching for the next optimal point.\n",
      "Iteration No: 50 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3545\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 51 started. Searching for the next optimal point.\n",
      "Iteration No: 51 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0206\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 52 started. Searching for the next optimal point.\n",
      "Iteration No: 52 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4361\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 53 started. Searching for the next optimal point.\n",
      "Iteration No: 53 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3494\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 54 started. Searching for the next optimal point.\n",
      "Iteration No: 54 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4117\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 55 started. Searching for the next optimal point.\n",
      "Iteration No: 55 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.5380\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 56 started. Searching for the next optimal point.\n",
      "Iteration No: 56 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2498\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 57 started. Searching for the next optimal point.\n",
      "Iteration No: 57 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2801\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 58 started. Searching for the next optimal point.\n",
      "Iteration No: 58 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7240\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 59 started. Searching for the next optimal point.\n",
      "Iteration No: 59 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2193\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 60 started. Searching for the next optimal point.\n",
      "Iteration No: 60 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9724\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 61 started. Searching for the next optimal point.\n",
      "Iteration No: 61 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.7909\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 62 started. Searching for the next optimal point.\n",
      "Iteration No: 62 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3160\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 63 started. Searching for the next optimal point.\n",
      "Iteration No: 63 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.2188\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 64 started. Searching for the next optimal point.\n",
      "Iteration No: 64 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9594\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 65 started. Searching for the next optimal point.\n",
      "Iteration No: 65 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8871\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 66 started. Searching for the next optimal point.\n",
      "Iteration No: 66 ended. Search finished for the next optimal point.\n",
      "Time taken: 8.0942\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 67 started. Searching for the next optimal point.\n",
      "Iteration No: 67 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3283\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 68 started. Searching for the next optimal point.\n",
      "Iteration No: 68 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.9370\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 69 started. Searching for the next optimal point.\n",
      "Iteration No: 69 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.2263\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 70 started. Searching for the next optimal point.\n",
      "Iteration No: 70 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8539\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 71 started. Searching for the next optimal point.\n",
      "Iteration No: 71 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4683\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 72 started. Searching for the next optimal point.\n",
      "Iteration No: 72 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.3375\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 73 started. Searching for the next optimal point.\n",
      "Iteration No: 73 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.4247\n",
      "Function value obtained: 0.6931\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 74 started. Searching for the next optimal point.\n",
      "Iteration No: 74 ended. Search finished for the next optimal point.\n",
      "Time taken: 7.8346\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n",
      "Iteration No: 75 started. Searching for the next optimal point.\n",
      "Iteration No: 75 ended. Search finished for the next optimal point.\n",
      "Time taken: 5.2584\n",
      "Function value obtained: 0.6935\n",
      "Current minimum: 0.6931\n"
     ]
    }
   ],
   "source": [
    "def _lrc_base_objective(params):\n",
    "    tol, C, max_iter = params\n",
    "\n",
    "    _lrc_base.set_params(tol=tol,\n",
    "                   C=C,\n",
    "                  max_iter=max_iter)\n",
    "\n",
    "    return -np.mean(cross_val_score(_lrc_base, X_train, y_train, cv=5, n_jobs=-1,\n",
    "                                    scoring=\"neg_log_loss\"))\n",
    "\n",
    "_lrc_base_space  = [(1, 5),                           # tol\n",
    "          (1, 100),                        # C \n",
    "                  (50,250)]                          #max_iter\n",
    "\n",
    "_lrc_base_res_gp = gp_minimize(_lrc_base_objective, \n",
    "              _lrc_base_space, base_estimator=None, \n",
    "            n_calls=75, n_random_starts=10, acq_func='gp_hedge', \n",
    "            acq_optimizer='lbfgs', x0=None, y0=None, random_state=None, \n",
    "            verbose=True, callback=None, n_points=1000, \n",
    "            n_restarts_optimizer=5, xi=0.01, kappa=1.96, \n",
    "            noise='gaussian', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f64b5edbdd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEYCAYAAABLOxEiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64b5e28750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_convergence(_lrc_base_res_gp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Assign the best parameters and check results. Then calibrate and check results again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_lrc_base_sk = LogisticRegression(penalty='l2', dual=False, tol=0.0001, \n",
    "                           C=51.0, fit_intercept=True, intercept_scaling=1, \n",
    "                           class_weight=None, random_state=None, \n",
    "                           solver='liblinear', max_iter=69, \n",
    "                           multi_class='ovr', verbose=0, \n",
    "                           warm_start=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_lrc_base_sk.tol ,_lrc_base_sk.C ,_lrc_base_sk.max_iter = _lrc_base_res_gp.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51687104882321566)\n",
      "('log_loss', ':', 0.69314166562958257)\n",
      "('precision_score', ':', 0.51510551085471379)\n",
      "('time', ':', 10.01988697052002)\n",
      "('accuracy_score', ':', 0.51351765923994319)\n",
      "('roc_auc_score', ':', 0.51632930160192791)\n",
      "('jaccard_similarity_score', ':', 0.51351765923994319)\n",
      "('recall_score', ':', 0.51864873127483946)\n",
      "('brier_score_loss', ':', 0.24999556298881076)\n",
      "('matthews_corrcoef', ':', 0.027000675302886749)\n",
      "('confusion_matrix', ':', array([[6605, 6388],\n",
      "       [6298, 6786]]))\n",
      "('hamming_loss', ':', 0.48648234076005675)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_lrc_base_sk, \"_lrc\", \"_lrc_base_sk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_lrc_base_sk_cal_cv = CalibratedClassifierCV(base_estimator=_lrc_base_sk, \n",
    "                                          method='sigmoid', cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.51160817585807949)\n",
      "('log_loss', ':', 0.6928333084241699)\n",
      "('precision_score', ':', 0.51634750116767869)\n",
      "('time', ':', 20.3553729057312)\n",
      "('accuracy_score', ':', 0.51436131456839362)\n",
      "('roc_auc_score', ':', 0.5165454893132847)\n",
      "('jaccard_similarity_score', ':', 0.51436131456839362)\n",
      "('recall_score', ':', 0.5069550596147967)\n",
      "('brier_score_loss', ':', 0.24984308023026941)\n",
      "('matthews_corrcoef', ':', 0.028777462198438561)\n",
      "('confusion_matrix', ':', array([[6780, 6213],\n",
      "       [6451, 6633]]))\n",
      "('hamming_loss', ':', 0.48563868543160638)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_lrc_base_sk_cal_cv, \"_lrc\", \"_lrc_base_sk_cal_cv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"_model_metrics_f8.pkl\", 'wb') as file:\n",
    "    pickle.dump(_model_metrics,file)\n",
    "f8 = pd.DataFrame(_model_metrics)\n",
    "f8.to_json('_model_metrics_f8.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Keras Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(220, input_dim=input_dim))\n",
    "    model.add(Dense(100))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "                  metrics=['binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "_krs = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.40353241924238903)\n",
      "('log_loss', ':', 0.69319647084525171)\n",
      "('precision_score', ':', 0.51488554145415732)\n",
      "('time', ':', 75.50204396247864)\n",
      "('accuracy_score', ':', 0.5078805077271159)\n",
      "('roc_auc_score', ':', 0.50944304182039279)\n",
      "('jaccard_similarity_score', ':', 0.5078805077271159)\n",
      "('recall_score', ':', 0.33177927239376337)\n",
      "('brier_score_loss', ':', 0.2500244810642952)\n",
      "('matthews_corrcoef', ':', 0.018166356811131053)\n",
      "('confusion_matrix', ':', array([[8903, 4090],\n",
      "       [8743, 4341]]))\n",
      "('hamming_loss', ':', 0.49211949227288415)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_krs, \"_krs\", \"_krs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Using hand optimized parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(220, input_dim=input_dim, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(25, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(8, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "_krs_base = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(220, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", input_dim=264)`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.66821582697071058)\n",
      "('log_loss', ':', 0.69334728382626398)\n",
      "('precision_score', ':', 0.50174483261111325)\n",
      "('time', ':', 190.1858949661255)\n",
      "('accuracy_score', ':', 0.50174483261111325)\n",
      "('roc_auc_score', ':', 0.51994718695152342)\n",
      "('jaccard_similarity_score', ':', 0.50174483261111325)\n",
      "('recall_score', ':', 1.0)\n",
      "('brier_score_loss', ':', 0.25009946113323561)\n",
      "('matthews_corrcoef', ':', 0.0)\n",
      "('confusion_matrix', ':', array([[    0, 12993],\n",
      "       [    0, 13084]]))\n",
      "('hamming_loss', ':', 0.49825516738888675)\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_krs_base, \"_krs\", \"_krs_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"_model_metrics_f9.pkl\", 'wb') as file:\n",
    "    pickle.dump(_model_metrics,file)\n",
    "f8 = pd.DataFrame(_model_metrics)\n",
    "f8.to_json('_model_metrics_f9.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _select_best(_metric):\n",
    "    _metric_dict = _model_metrics[_metric]\n",
    "    _best_subtype = []\n",
    "    for _model_types, _model_subtypes in _metric_dict.items():\n",
    "        _best_subtype.append(_model_subtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Stacked CV without features in the meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Redefine Keras\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=input_dim_krs_scv, init=init, activation='relu'))\n",
    "    model.add(Dense(3, init=init, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                  metrics=['binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "input_dim_krs_scv = 16\n",
    "_krs_scv = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_sclf_meta_noF = StackingCVClassifier(classifiers=[_sgd_base_sk, _rfc_base_sk, _gbc_base_sk, _mlp_base, _xgb_base_sk,\n",
    "                                    _etc_base_sk, _dtc_base_sk, _lrc_base_sk],\n",
    "                              meta_classifier= _krs_scv, stratify=True,\n",
    "                            n_folds=3, use_probas=True, verbose=1,use_features_in_secondary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier2: randomforestclassifier (2/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier3: gradientboostingclassifier (3/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           28.99s\n",
      "         2           1.3862           29.41s\n",
      "         3           1.3861           28.80s\n",
      "         4           1.3861           27.81s\n",
      "         5           1.3860           27.18s\n",
      "         6           1.3860           27.08s\n",
      "         7           1.3860           26.69s\n",
      "         8           1.3859           26.50s\n",
      "         9           1.3859           26.56s\n",
      "        10           1.3859           26.04s\n",
      "        20           1.3855           24.91s\n",
      "        30           1.3851           23.49s\n",
      "        40           1.3848           22.21s\n",
      "        50           1.3846           20.56s\n",
      "        60           1.3844           19.14s\n",
      "        70           1.3842           17.69s\n",
      "        80           1.3841           16.24s\n",
      "        90           1.3839           14.80s\n",
      "       100           1.3837           13.41s\n",
      "       200           1.3825            0.00s\n",
      "Training and fitting fold 2 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           26.69s\n",
      "         2           1.3862           28.46s\n",
      "         3           1.3861           28.33s\n",
      "         4           1.3861           28.48s\n",
      "         5           1.3860           28.02s\n",
      "         6           1.3860           27.71s\n",
      "         7           1.3859           27.68s\n",
      "         8           1.3859           27.32s\n",
      "         9           1.3858           26.83s\n",
      "        10           1.3858           26.68s\n",
      "        20           1.3855           24.82s\n",
      "        30           1.3852           23.29s\n",
      "        40           1.3850           21.77s\n",
      "        50           1.3847           20.33s\n",
      "        60           1.3846           18.92s\n",
      "        70           1.3844           17.45s\n",
      "        80           1.3842           16.02s\n",
      "        90           1.3841           14.57s\n",
      "       100           1.3840           13.22s\n",
      "       200           1.3829            0.00s\n",
      "Training and fitting fold 3 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           27.38s\n",
      "         2           1.3862           27.99s\n",
      "         3           1.3861           28.22s\n",
      "         4           1.3861           27.95s\n",
      "         5           1.3860           27.90s\n",
      "         6           1.3860           27.63s\n",
      "         7           1.3859           27.35s\n",
      "         8           1.3859           27.12s\n",
      "         9           1.3858           26.84s\n",
      "        10           1.3858           26.47s\n",
      "        20           1.3854           25.07s\n",
      "        30           1.3851           23.67s\n",
      "        40           1.3848           22.27s\n",
      "        50           1.3846           20.67s\n",
      "        60           1.3844           19.19s\n",
      "        70           1.3842           17.70s\n",
      "        80           1.3841           16.33s\n",
      "        90           1.3839           14.86s\n",
      "       100           1.3837           13.42s\n",
      "       200           1.3826            0.00s\n",
      "Fitting classifier4: mlpclassifier (4/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Iteration 1, loss = 0.69476670\n",
      "Validation score: 0.507004\n",
      "Iteration 2, loss = 0.69366105\n",
      "Validation score: 0.507511\n",
      "Iteration 3, loss = 0.69313848\n",
      "Validation score: 0.504263\n",
      "Iteration 4, loss = 0.69295646\n",
      "Validation score: 0.502436\n",
      "Iteration 5, loss = 0.69247512\n",
      "Validation score: 0.502944\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training and fitting fold 2 of 3...\n",
      "Iteration 6, loss = 0.69343055\n",
      "Validation score: 0.503045\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training and fitting fold 3 of 3...\n",
      "Iteration 7, loss = 0.69303209\n",
      "Validation score: 0.510759\n",
      "Iteration 8, loss = 0.69249661\n",
      "Validation score: 0.512180\n",
      "Iteration 9, loss = 0.69228177\n",
      "Validation score: 0.508222\n",
      "Iteration 10, loss = 0.69206974\n",
      "Validation score: 0.504974\n",
      "Iteration 11, loss = 0.69175693\n",
      "Validation score: 0.507308\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Fitting classifier5: xgbclassifier (5/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier6: extratreesclassifier (6/8)\n",
      "Training and fitting fold 1 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and fitting fold 2 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and fitting fold 3 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: decisiontreeclassifier (7/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier8: logisticregression (8/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           44.40s\n",
      "         2           1.3862           43.57s\n",
      "         3           1.3861           43.91s\n",
      "         4           1.3861           43.20s\n",
      "         5           1.3861           42.56s\n",
      "         6           1.3860           42.64s\n",
      "         7           1.3860           42.32s\n",
      "         8           1.3859           42.04s\n",
      "         9           1.3859           41.72s\n",
      "        10           1.3859           41.30s\n",
      "        20           1.3855           39.32s\n",
      "        30           1.3853           37.24s\n",
      "        40           1.3851           34.87s\n",
      "        50           1.3849           32.10s\n",
      "        60           1.3848           29.93s\n",
      "        70           1.3846           27.70s\n",
      "        80           1.3845           25.40s\n",
      "        90           1.3844           23.20s\n",
      "       100           1.3843           21.02s\n",
      "       200           1.3835            0.00s\n",
      "Iteration 12, loss = 0.69253158\n",
      "Validation score: 0.504433"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    5.4s finished\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(9, activation=\"relu\", kernel_initializer=\"glorot_uniform\", input_dim=16)`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "('f1_score', ':', 0.66821582697071058)\n",
      "('log_loss', ':', 0.69314530124399898)\n",
      "('precision_score', ':', 0.50174483261111325)\n",
      "('time', ':', 327.9201741218567)\n",
      "('accuracy_score', ':', 0.50174483261111325)\n",
      "('roc_auc_score', ':', 0.5)\n",
      "('jaccard_similarity_score', ':', 0.50174483261111325)\n",
      "('recall_score', ':', 1.0)\n",
      "('brier_score_loss', ':', 0.24999905710345735)\n",
      "('matthews_corrcoef', ':', 0.0)\n",
      "('confusion_matrix', ':', array([[    0, 12993],\n",
      "       [    0, 13084]]))\n",
      "('hamming_loss', ':', 0.49825516738888675)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:49: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "#_sclf_meta_noF.fit(X_train,y_train)\n",
    "_compile_model(_sclf_meta_noF, \"_sclf_meta_noF\", \"_sclf_meta_noF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"_model_metrics_f10.pkl\", 'wb') as file:\n",
    "    pickle.dump(_model_metrics,file)\n",
    "f10 = pd.DataFrame(_model_metrics)\n",
    "f10.to_json('_model_metrics_f10.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Stacked CV with features in the meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Redefine Keras\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(220, input_dim=input_dim_krs_base_sclf_meta_useF, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(25, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(8, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "input_dim_krs_base_sclf_meta_useF = X_train.shape[1] + 16\n",
    "_krs_base_sclf_meta_useF = KerasClassifier(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_sclf_meta_useF = StackingCVClassifier(classifiers=[_sgd_base_sk, _rfc_base_sk, _gbc_base_sk, _mlp_base, _xgb_base_sk,\n",
    "                                    _etc_base_sk, _dtc_base_sk, _lrc_base_sk],\n",
    "                              meta_classifier= _krs_base_sclf_meta_useF, stratify=True,\n",
    "                            n_folds=3, use_probas=True, verbose=1,use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 8 classifiers...\n",
      "Fitting classifier1: sgdclassifier (1/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier2: randomforestclassifier (2/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier3: gradientboostingclassifier (3/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           27.58s\n",
      "         2           1.3862           28.12s\n",
      "         3           1.3861           28.45s\n",
      "         4           1.3861           28.16s\n",
      "         5           1.3860           27.51s\n",
      "         6           1.3860           27.53s\n",
      "         7           1.3859           27.31s\n",
      "         8           1.3859           26.85s\n",
      "         9           1.3859           26.49s\n",
      "        10           1.3859           26.31s\n",
      "        20           1.3855           25.06s\n",
      "        30           1.3852           23.71s\n",
      "        40           1.3849           22.44s\n",
      "        50           1.3847           20.88s\n",
      "        60           1.3845           19.40s\n",
      "        70           1.3843           17.88s\n",
      "        80           1.3842           16.39s\n",
      "        90           1.3840           14.85s\n",
      "       100           1.3839           13.43s\n",
      "       200           1.3827            0.00s\n",
      "Training and fitting fold 2 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           28.28s\n",
      "         2           1.3862           27.82s\n",
      "         3           1.3861           26.40s\n",
      "         4           1.3861           25.69s\n",
      "         5           1.3861           25.96s\n",
      "         6           1.3860           26.02s\n",
      "         7           1.3860           26.21s\n",
      "         8           1.3859           26.12s\n",
      "         9           1.3859           26.20s\n",
      "        10           1.3858           26.04s\n",
      "        20           1.3854           25.06s\n",
      "        30           1.3851           23.50s\n",
      "        40           1.3849           21.97s\n",
      "        50           1.3847           20.52s\n",
      "        60           1.3844           19.13s\n",
      "        70           1.3843           17.62s\n",
      "        80           1.3841           16.23s\n",
      "        90           1.3839           14.84s\n",
      "       100           1.3838           13.43s\n",
      "       200           1.3826            0.00s\n",
      "Training and fitting fold 3 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           30.30s\n",
      "         2           1.3862           28.85s\n",
      "         3           1.3861           28.52s\n",
      "         4           1.3861           28.40s\n",
      "         5           1.3860           28.18s\n",
      "         6           1.3860           28.08s\n",
      "         7           1.3859           27.86s\n",
      "         8           1.3859           27.83s\n",
      "         9           1.3858           27.64s\n",
      "        10           1.3858           27.44s\n",
      "        20           1.3854           25.94s\n",
      "        30           1.3851           24.42s\n",
      "        40           1.3848           22.73s\n",
      "        50           1.3846           21.11s\n",
      "        60           1.3844           19.57s\n",
      "        70           1.3842           18.11s\n",
      "        80           1.3841           16.62s\n",
      "        90           1.3839           15.11s\n",
      "       100           1.3838           13.63s\n",
      "       200           1.3826            0.00s\n",
      "Fitting classifier4: mlpclassifier (4/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Iteration 1, loss = 0.69458932\n",
      "Validation score: 0.512079\n",
      "Iteration 2, loss = 0.69373074\n",
      "Validation score: 0.507917\n",
      "Iteration 3, loss = 0.69335539\n",
      "Validation score: 0.520808\n",
      "Iteration 4, loss = 0.69305021\n",
      "Validation score: 0.519996\n",
      "Iteration 5, loss = 0.69273257\n",
      "Validation score: 0.514312\n",
      "Iteration 6, loss = 0.69243650\n",
      "Validation score: 0.520503\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training and fitting fold 2 of 3...\n",
      "Iteration 7, loss = 0.69312968\n",
      "Validation score: 0.506192\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Training and fitting fold 3 of 3...\n",
      "Iteration 8, loss = 0.69274330\n",
      "Validation score: 0.516849\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Fitting classifier5: xgbclassifier (5/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier6: extratreesclassifier (6/8)\n",
      "Training and fitting fold 1 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and fitting fold 2 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and fitting fold 3 of 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    3.2s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting classifier7: decisiontreeclassifier (7/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "Fitting classifier8: logisticregression (8/8)\n",
      "Training and fitting fold 1 of 3...\n",
      "Training and fitting fold 2 of 3...\n",
      "Training and fitting fold 3 of 3...\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3862           44.55s\n",
      "         2           1.3862           46.16s\n",
      "         3           1.3862           45.34s\n",
      "         4           1.3861           43.57s\n",
      "         5           1.3861           43.67s\n",
      "         6           1.3860           43.32s\n",
      "         7           1.3860           42.77s\n",
      "         8           1.3860           42.64s\n",
      "         9           1.3859           42.51s\n",
      "        10           1.3859           42.07s\n",
      "        20           1.3855           39.62s\n",
      "        30           1.3853           37.38s\n",
      "        40           1.3851           35.12s\n",
      "        50           1.3849           32.82s\n",
      "        60           1.3847           30.67s\n",
      "        70           1.3846           28.39s\n",
      "        80           1.3845           26.09s\n",
      "        90           1.3844           23.76s\n",
      "       100           1.3843           21.54s\n",
      "       200           1.3835            0.00s\n",
      "Iteration 9, loss = 0.69257929\n",
      "Validation score: 0.514516\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    5.6s finished\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(220, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", input_dim=280)`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.0)\n",
      "('log_loss', ':', 0.69445111332630172)\n",
      "('precision_score', ':', 0.0)\n",
      "('time', ':', 482.451553106308)\n",
      "('accuracy_score', ':', 0.49825516738888675)\n",
      "('roc_auc_score', ':', 0.50907004566553637)\n",
      "('jaccard_similarity_score', ':', 0.49825516738888675)\n",
      "('recall_score', ':', 0.0)\n",
      "('brier_score_loss', ':', 0.25065125410715294)\n",
      "('matthews_corrcoef', ':', 0.0)\n",
      "('confusion_matrix', ':', array([[12993,     0],\n",
      "       [13084,     0]]))\n",
      "('hamming_loss', ':', 0.50174483261111325)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:49: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_sclf_meta_useF, \"_sclf_meta_useF\", \"_sclf_meta_useF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ensemble softvoting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Redefine Keras\n",
    "def create_model(optimizer='adam', init='glorot_uniform'):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(220, input_dim=input_dim_krs_base_vclf_meta_soft, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(100, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(25, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(8, init=init, activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(.25))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd,\n",
    "                  metrics=['binary_crossentropy'])\n",
    "    return model\n",
    "\n",
    "_krs_base_vclf_meta_soft = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "input_dim_krs_base_vclf_meta_soft = X_train.shape[1]\n",
    "_eclf_meta_soft = EnsembleVoteClassifier(clfs=[_sgd_base_sk, _rfc_base_sk, _gbc_base_sk, _mlp_base, _xgb_base_sk,\n",
    "                                    _etc_base_sk, _dtc_base_sk, _lrc_base_sk,_krs_base_vclf_meta_soft], voting='soft', \n",
    "                                         refit=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 9 classifiers...\n",
      "Fitting clf1: sgdclassifier (1/9)\n",
      "Fitting clf2: randomforestclassifier (2/9)\n",
      "Fitting clf3: gradientboostingclassifier (3/9)\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3863           41.32s\n",
      "         2           1.3862           43.49s\n",
      "         3           1.3862           43.57s\n",
      "         4           1.3861           42.22s\n",
      "         5           1.3861           42.25s\n",
      "         6           1.3860           42.15s\n",
      "         7           1.3860           41.70s\n",
      "         8           1.3859           41.65s\n",
      "         9           1.3859           41.47s\n",
      "        10           1.3859           41.23s\n",
      "        20           1.3855           38.98s\n",
      "        30           1.3853           36.57s\n",
      "        40           1.3851           34.17s\n",
      "        50           1.3849           32.04s\n",
      "        60           1.3847           29.89s\n",
      "        70           1.3846           27.77s\n",
      "        80           1.3845           25.48s\n",
      "        90           1.3844           23.28s\n",
      "       100           1.3843           21.11s\n",
      "       200           1.3834            0.00s\n",
      "Fitting clf4: mlpclassifier (4/9)\n",
      "Iteration 1, loss = 0.69447173\n",
      "Validation score: 0.508696\n",
      "Iteration 2, loss = 0.69382948\n",
      "Validation score: 0.505989\n",
      "Iteration 3, loss = 0.69334056\n",
      "Validation score: 0.514651\n",
      "Iteration 4, loss = 0.69302924\n",
      "Validation score: 0.513568\n",
      "Iteration 5, loss = 0.69278643\n",
      "Validation score: 0.513095\n",
      "Iteration 6, loss = 0.69248604\n",
      "Validation score: 0.505718\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "Fitting clf5: xgbclassifier (5/9)\n",
      "Fitting clf6: extratreesclassifier (6/9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 326 out of 326 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting clf7: decisiontreeclassifier (7/9)\n",
      "Fitting clf8: logisticregression (8/9)\n",
      "Fitting clf9: kerasclassifier (9/9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(220, activation=\"tanh\", kernel_initializer=\"glorot_uniform\", input_dim=264)`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(100, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(25, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"tanh\", kernel_initializer=\"glorot_uniform\")`\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=64)]: Done  72 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=64)]: Done 326 out of 326 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('f1_score', ':', 0.5327061263797318)\n",
      "('log_loss', ':', 0.6925374893352364)\n",
      "('precision_score', ':', 0.51681759379042691)\n",
      "('time', ':', 458.1645178794861)\n",
      "('accuracy_score', ':', 0.51620201710319435)\n",
      "('roc_auc_score', ':', 0.52078113198925657)\n",
      "('jaccard_similarity_score', ':', 0.51620201710319435)\n",
      "('recall_score', ':', 0.54960256802201157)\n",
      "('brier_score_loss', ':', 0.24969531053110208)\n",
      "('matthews_corrcoef', ':', 0.032242677859388065)\n",
      "('confusion_matrix', ':', array([[6270, 6723],\n",
      "       [5893, 7191]]))\n",
      "('hamming_loss', ':', 0.48379798289680559)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/metbron/.local/lib/python2.7/site-packages/ipykernel/__main__.py:49: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    }
   ],
   "source": [
    "_compile_model(_eclf_meta_soft, \"_eclf_meta_soft\", \"_eclf_meta_soft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ensemble hard voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_eclf_meta_hard = VotingClassifier(estimators=[('_sgd_base_sk',_sgd_base_sk), ('_rfc_base_sk',_rfc_base_sk), \n",
    "                                    ('_gbc_base_sk',_gbc_base_sk), ('_mlp_base',_mlp_base), \n",
    "                                    ('_xgb_base_sk',_xgb_base_sk), ('_etc_base_sk',_etc_base_sk), \n",
    "                                    ('_dtc_base_sk',_dtc_base_sk), ('_lrc_base_sk',_lrc_base_sk), \n",
    "                                    ('_krs_base',_krs_base)], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_compile_model(_eclf_meta_hard, \"_eclf_meta_hard\", \"_eclf_meta_hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(\"_model_metrics.pkl\", 'wb') as file:\n",
    "    pickle.dump(_model_metrics,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = pd.DataFrame(_model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f.to_json('_model_metrics.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
